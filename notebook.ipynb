{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import *\n",
    "from implementations import *\n",
    "\n",
    "# from test_utils import test\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run de A a Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading  data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, train_ids, test_ids = load_csv_data(\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.genfromtxt(\"dataset/x_test.csv\", delimiter=\",\", dtype = str, max_rows=1)\n",
    "labels = np.delete(labels,0) # delete the label 'id' as we dont have it in x_train and x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the high number of features with all different exceptions values and linearity, we decided to select manually the features we found relevant. The list below is the name of the feature, the exception values that we have to remplace, and wheter we remplace by majority (True) or by the mean (False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = [(\"MSCODE\", [], True, None),\n",
    "            (\"_HCVU651\", [9], True, None),\n",
    "            (\"_RFHYPE5\", [9], True, None),\n",
    "            (\"_RFCHOL\", [9], True, None),\n",
    "            (\"_RACE\",[9], True, None),\n",
    "            (\"_BMI5\",[], False, None),\n",
    "            (\"_EDUCAG\",[9], True, None),\n",
    "            (\"_INCOMG\",[9], True, None),\n",
    "            (\"_DRNKWEK\",[99900], False, None),\n",
    "            (\"_SMOKER3\",[9], True, None),\n",
    "            (\"_FRUTSUM\",[], False, None),\n",
    "            (\"_VEGESUM\",[], False, None),\n",
    "            (\"PA1MIN_\",[], False, None),\n",
    "            (\"GENHLTH\",[7,9], False, None),\n",
    "            (\"CHECKUP1\",[7,9], False, None),\n",
    "            (\"MENTHLTH\",[77, 99], False, 88), #88 -> 0 \n",
    "            (\"BPHIGH4\",[7,9], True, None),\n",
    "            (\"BPMEDS\",[7,9], True, None),\n",
    "            (\"TOLDHI2\",[7,9], True, None),\n",
    "            (\"CHCOCNCR\",[7,8,9], True, None),\n",
    "            (\"DIABETE3\",[7,8,9], True, None),\n",
    "            (\"SEX\",[], True, None),\n",
    "            (\"QLACTLM2\",[7,9], True, None),\n",
    "            (\"AVEDRNK2\",[77, 99], False, None),\n",
    "            (\"EXERANY2\",[7,9], True, None),\n",
    "            (\"SHINGLE2\", [7,9], True, None),\n",
    "            (\"LMTJOIN3\", [7,9], True, None),\n",
    "            (\"CVDASPRN\", [7,9], True, None),\n",
    "            (\"PHYSHLTH\",[77,99], False, 88), #88 -> 0 \n",
    "            (\"POORHLTH\",[77,99], False, 88), # 88 -> 0  \n",
    "            (\"HLTHPLN1\",[7,9], True, None),\n",
    "            (\"BLOODCHO\", [7,9], True, None),\n",
    "            (\"CHOLCHK\",[7,9],True, None),\n",
    "            #(\"CVDINFR4\", [7,9], True, None),\n",
    "            #(\"CVDCRHD4\", [7,9], True, None),\n",
    "            (\"CVDSTRK3\", [7,9], True, None),\n",
    "            (\"ASTHMA3\", [7,9], True, None),\n",
    "            (\"ASTHNOW\", [7,9], True, None),\n",
    "            (\"CHCSCNCR\", [7,9], True, None),\n",
    "            (\"CHCCOPD1\",[7,9], True, None),\n",
    "            (\"HAVARTH3\", [7,9], True, None),\n",
    "            (\"ADDEPEV2\", [7,9], True, None),\n",
    "            (\"CHCKIDNY\", [7,9], True, None),\n",
    "            (\"DIABAGE2\", [98,99], False, None),\n",
    "            (\"MARITAL\", [9], True, None),\n",
    "            (\"RENTHOM1\", [7,9], True, None),\n",
    "            (\"EMPLOY1\", [9], True, None),\n",
    "            (\"CHILDREN\", [99], False, 88), # 88 -> 0 \n",
    "            (\"INCOME2\", [77,99], True, None),\n",
    "            (\"INTERNET\", [7,9], True, None),\n",
    "            (\"QLACTLM2\", [7,9], True, None),\n",
    "            (\"USEEQUIP\", [7,9], True, None),\n",
    "            (\"BLIND\", [7,9], True, None),\n",
    "            (\"DECIDE\", [7,9], True, None),\n",
    "            (\"DIFFWALK\", [7,9], True, None),\n",
    "            (\"DIFFDRES\", [7,9], True, None),\n",
    "            (\"DIFFALON\", [7,9], True, None),\n",
    "            (\"SMOKE100\", [7,9], True, None),\n",
    "            (\"SMOKDAY2\", [7,9], True, None),\n",
    "            (\"STOPSMK2\", [7,9], True, None),\n",
    "            (\"USENOW3\", [7,9], True, None), \n",
    "            (\"DRNK3GE5\", [77,99],False, 88)  ## 88 -> 0 \n",
    "            ]\n",
    "\n",
    "cleaned_x_train = clean_data(labels, label_list, x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,\n",
       "        -4.89451372e-01,  2.00000000e+00,  3.00000000e+00],\n",
       "       [ 5.00000000e+00,  1.00000000e+00,  2.00000000e+00, ...,\n",
       "        -9.33005477e-17,  2.00000000e+00,  3.00000000e+00],\n",
       "       [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,\n",
       "        -6.70001037e-01,  2.00000000e+00,  3.00000000e+00],\n",
       "       ...,\n",
       "       [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,\n",
       "        -6.20760219e-01,  2.00000000e+00,  3.00000000e+00],\n",
       "       [ 5.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,\n",
       "        -7.71765394e-01,  2.00000000e+00,  3.00000000e+00],\n",
       "       [ 1.00000000e+00,  1.00000000e+00,  2.00000000e+00, ...,\n",
       "        -8.17723491e-01,  2.00000000e+00,  3.00000000e+00]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then check that we have enough data in our features, i.e. there is not an exagerated amount of nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# want to see which labels are way to small\n",
    "\n",
    "for label in label_list:\n",
    "    l, _, _ = label\n",
    "    id = np.where(labels == l)[0][0]\n",
    "    x = x_train[:][id]\n",
    "\n",
    "    # Count the number of NaN values\n",
    "    nans= np.count_nonzero(np.isnan(x))\n",
    "    nan_perc = nans/len(x) *100\n",
    "    #print(nan_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check that our features are uncorrelated as it would lead to less good results, but we saw that the uncorrelated data had the same dimension as the original cleaned data, so no changes were made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328135, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(328135, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_matrix = np.corrcoef(cleaned_x_train, rowvar=False)\n",
    "correlation_threshold = 0.7\n",
    "uncorrelated_indices = np.where(np.abs(correlation_matrix) < correlation_threshold)\n",
    "uncorrelated_columns = np.unique(uncorrelated_indices[1])\n",
    "uncorrelated_data = cleaned_x_train[:, uncorrelated_columns]\n",
    "print(uncorrelated_data.shape)\n",
    "cleaned_x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "We here choose which function we want to train our data with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(701,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_ = 0.0001\n",
    "degree = 25\n",
    "## tx is cleaned data \n",
    "poly = build_poly(cleaned_x_train,degree)\n",
    "w , loss = ridge_regression(y_train,poly,lambda_)\n",
    "w.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean squared errors gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.0001\n",
    "max_iters = 1000\n",
    "w_initial = np.zeros(cleaned_x_train.shape[1])\n",
    "\n",
    "w, loss = mean_squared_error_gd(y_train, cleaned_x_train, w_initial, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15174410864282326"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean squared error sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_1, y_train_1, x_test_1, y_test_1 = split_train_test(y_train, x_train, 0.7)\n",
    "cleaned_x_train_1 = clean_data(labels, label_list, x_train_1)\n",
    "cleaned_x_test_1 = clean_data(labels, label_list, x_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y pred : '[4.37600356e+25 5.52661106e+25 4.51852034e+25 ... 3.91049147e+25\n",
      " 5.08228170e+25 5.06617256e+25]'.\n"
     ]
    }
   ],
   "source": [
    "x_train_1, y_train_1, x_test_1, y_test_1 = split_train_test(y_train, x_train, 0.7)\n",
    "cleaned_x_train_1 = clean_data(labels, label_list, x_train_1)\n",
    "cleaned_x_test_1 = clean_data(labels, label_list, x_test_1)\n",
    "\n",
    "gamma = 0.03684211157894737\n",
    "max_iters = 300\n",
    "#w_initial = np.zeros(cleaned_x_train.shape[1])\n",
    "initial_w = np.zeros(cleaned_x_train_1.shape[1])\n",
    "# remettre a 0 entre chaque run ? \n",
    "w = []\n",
    "loss = 0\n",
    "yp = []\n",
    "acc = 0\n",
    "f1 = 0\n",
    "\n",
    "#w, loss = mean_squared_error_sgd(y_train, cleaned_x_train, w_initial, max_iters, gamma)\n",
    "w, loss = mean_squared_error_gd(y_train_1, cleaned_x_train_1, initial_w, max_iters, gamma)\n",
    "yp = predict_labels_mse(w,cleaned_x_test_1)\n",
    "#yp = predict_labels_logistic(w, cleaned_x_test_1)\n",
    "\n",
    "# mesure accuracy\n",
    "acc = measure_accuracy(y_test_1, yp)\n",
    "f1 = measure_f1_score(y_test_1, yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16356988284456384"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.00360482144868762"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Least squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, loss = least_squares(y_train, cleaned_x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\duval\\Documents\\GitHub\\ML_project1\\helpers.py:96: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0 / (1 + np.exp(-t))\n",
      "c:\\Users\\duval\\Documents\\GitHub\\ML_project1\\helpers.py:115: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -np.mean(y * np.log(pred) + (1 - y) * np.log(1 - pred))\n",
      "c:\\Users\\duval\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\_methods.py:180: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n"
     ]
    }
   ],
   "source": [
    "max_iters = 1000\n",
    "gamma = 0.01\n",
    "w_initial = np.zeros(cleaned_x_train.shape[1])\n",
    "w, loss = logistic_regression(y_train, cleaned_x_train, w_initial, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reg logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iters = 1000\n",
    "gamma = 0.01\n",
    "lambda_ = 0.001\n",
    "w_initial = np.zeros(cleaned_x_train.shape[1])\n",
    "w, loss = reg_logistic_regression(y_train, cleaned_x_train, lambda_, w_initial, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(w)\n",
    "#print(loss)\n",
    "#print(len(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "\n",
    "We then test our data, cleaning the test dataset and building predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up x test\n",
    "\n",
    "cleaned_x_test = clean_data(labels, label_list, x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109379, 701)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only used for ridge\n",
    "poly_test = build_poly(cleaned_x_test,degree)\n",
    "poly_test.shape                                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction\n",
    "\n",
    "Use the correct prediction function depending on which train method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp = predict_labels_mse(w,cleaned_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00000000e+000 0.00000000e+000 0.00000000e+000 ... 1.19096188e-304\n",
      " 0.00000000e+000 0.00000000e+000]\n"
     ]
    }
   ],
   "source": [
    "yp = predict_labels_logistic(w,cleaned_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(np.where(y_pred == 1)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSV Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_submission(test_ids,yp,\"outputs/ridge_degre25_200features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split for our own cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####read me or smth\n",
    "\n",
    "- N c'est le nombre de loops\n",
    "- pour l'instant ca loop sur gamma mais si tu veux changer de param tu peux le modifier\n",
    "- initial_w, accs et f1s pas besoin de changer\n",
    "\n",
    "Utilise pas ridge i guess tfacon c'est pas celle qui nous interesse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_1, y_train_1, x_test_1, y_test_1 = split_train_test(y_train, x_train, 0.7)\n",
    "cleaned_x_train_1 = clean_data(labels, label_list, x_train_1)\n",
    "cleaned_x_test_1 = clean_data(labels, label_list, x_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y pred : '[-0.80789572 -0.80789572 -0.80789572 ... -0.80789572 -0.80789572\n",
      " -0.80789572]'.\n",
      "y pred : '[-0.57960261 -1.04903954 -0.75116857 ... -0.75180709 -0.93336801\n",
      " -1.01151047]'.\n",
      "y pred : '[-0.58225667 -1.08135794 -0.78217306 ... -0.78220046 -0.9489452\n",
      " -1.05288827]'.\n",
      "y pred : '[-0.55466114 -1.07539417 -0.77138072 ... -0.82376515 -0.95251885\n",
      " -1.05176642]'.\n",
      "y pred : '[-0.52821733 -1.07309483 -0.76749943 ... -0.8070941  -0.95027453\n",
      " -1.05359174]'.\n",
      "y pred : '[-0.52443741 -1.07448694 -0.76840808 ... -0.79364848 -0.95201939\n",
      " -1.05483073]'.\n",
      "y pred : '[-0.51546931 -1.07555611 -0.77880054 ... -0.79933347 -0.95063816\n",
      " -1.05038205]'.\n",
      "y pred : '[-0.52920179 -1.07696881 -0.77928535 ... -0.8059991  -0.94920432\n",
      " -1.049947  ]'.\n",
      "y pred : '[-0.5568357  -1.07594346 -0.78954365 ... -0.79117519 -0.94968318\n",
      " -1.05205936]'.\n",
      "y pred : '[-0.56453225 -1.07726911 -0.79026362 ... -0.78773177 -0.95063491\n",
      " -1.0520951 ]'.\n",
      "y pred : '[-0.56484202 -1.07669393 -0.79180093 ... -0.79593705 -0.95084241\n",
      " -1.053054  ]'.\n",
      "y pred : '[ 3.13548096 -1.08264459 -0.78999053 ... -0.79166716 -0.95715916\n",
      " -1.06622988]'.\n",
      "y pred : '[-0.57083298 -1.07300525 -0.79331802 ... -0.80785489 -0.95176398\n",
      " -1.05152741]'.\n",
      "y pred : '[-0.40153471 -1.08078541 -0.79814823 ... -0.79775758 -0.96017775\n",
      " -1.0602069 ]'.\n",
      "y pred : '[-1.2283269  -1.06913903 -0.79993831 ... -0.84322557 -0.95133867\n",
      " -1.03762211]'.\n",
      "y pred : '[-0.28327547 -1.07626867 -0.79145005 ... -0.80306146 -0.95369806\n",
      " -1.04586071]'.\n",
      "y pred : '[-0.91126435 -1.0707907  -0.87772588 ... -0.66770098 -0.90511526\n",
      " -1.06160557]'.\n",
      "y pred : '[-37.59234643  -1.32352753  19.7420033  ...  -0.3049467    0.24429216\n",
      "  -2.29065842]'.\n",
      "y pred : '[-1.87383603 -1.07312177 -0.67001847 ... -0.82483255 -0.94273274\n",
      " -1.08104482]'.\n",
      "y pred : '[-4.6603111  -1.08804289 -0.65200544 ... -1.16405311 -0.98858638\n",
      " -1.11832718]'.\n",
      "y pred : '[-2.76889986 -1.07907419 -0.75207299 ... -1.0355611  -0.91811928\n",
      " -1.05327334]'.\n",
      "y pred : '[-6.32703877 -1.06883356 -1.52509924 ... -1.80086208 -0.76595561\n",
      " -1.06415598]'.\n",
      "y pred : '[-5.33160671 -1.02266339 -0.54014477 ... -1.13865375 -0.98149669\n",
      " -1.36425192]'.\n",
      "y pred : '[-12.07659319  -1.21454314   0.52856783 ...  -0.76833847  -0.87619753\n",
      "  -0.81732759]'.\n",
      "y pred : '[ 12.97670916   1.82025175 -11.11184691 ... -13.59254014  -1.20722296\n",
      "   6.68409506]'.\n"
     ]
    }
   ],
   "source": [
    "N = 10\n",
    "max_iters = 300\n",
    "\n",
    "gammas = np.linspace(0.00000001, 0.1, N)\n",
    "#gammas = [0.018,0.185,0.019,0.0195,0.020]\n",
    "degree = range(25)\n",
    "#degree = 19\n",
    "#gammas = np.linspace(0.01,0.001,N)\n",
    "#gammas = np.linspace(0.00001, 0.1, N)\n",
    "\n",
    "lambda_ = 0.01\n",
    "#lambda_ = np.linspace(0.001, 0.1, N)\n",
    "\n",
    "initial_w = np.zeros(cleaned_x_train_1.shape[1])\n",
    "accs = []\n",
    "f1s = []\n",
    "\n",
    "for deg in degree:\n",
    "    #print(\"Gamma : '{}'.\".format(gamma))\n",
    "    # train\n",
    "    # choisi la methode de train qui t'interesse\n",
    "    poly_train = build_poly(cleaned_x_train_1, deg)\n",
    "    w, loss = ridge_regression(y_train_1, poly_train, lambda_)\n",
    "    #w, loss = mean_squared_error_gd(y_train_1, cleaned_x_train_1, initial_w, max_iters, gamma)\n",
    "    ## remplacer gamma par lambda \n",
    "    #w, loss = reg_logistic_regression(y_train_1, cleaned_x_train_1, lambda_, initial_w, max_iters, gamma)\n",
    "    #predict \n",
    "    # choisi la methode de test qui t'interresse (commente l'autre)\n",
    "    poly_test = build_poly(cleaned_x_test_1, deg)\n",
    "    yp = predict_labels_mse(w,poly_test)\n",
    "    #yp = predict_labels_logistic(w, cleaned_x_test_1)\n",
    "\n",
    "    # mesure accuracy\n",
    "    acc = measure_accuracy(y_test_1, yp)\n",
    "    f1 = measure_f1_score(y_test_1, yp)\n",
    "    accs.append(acc)\n",
    "    f1s.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6853921170255993, 0.7082486793986185, 0.6965258025193011, 0.7804043071921983, 0.8285757822023567, 0.9038906948394961, 0.9038297440065014, 0.7992685900040634, 0.891395774075579, 0.8841019910605445]\n",
      "[0.12588202088625458, 0.1418668578941078, 0.13005241700640652, 0.10343826469246402, 0.20057795253209532, 0.040369205801805454, 0.03663376411926325, 0.12527667109340415, 0.2394536529842783, 0.23290526457338803]\n"
     ]
    }
   ],
   "source": [
    "print(accs)\n",
    "print(f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08900000000000001"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_ = np.linspace(0.001, 0.1, N)\n",
    "lambda_[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of elements above the threshold:  [10, 11]\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.19\n",
    "# Get the indices where values are greater than the threshold\n",
    "indices_above_threshold = [i for i, value in enumerate(f1s) if value > threshold]\n",
    "\n",
    "# Sort the indices\n",
    "indices_above_threshold.sort()\n",
    "\n",
    "print(\"Indices of elements above the threshold: \", indices_above_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.63 / 0.219 : entre 0.0156 et 0.0159 \n",
    "0.837 : 0.153 : 0.0156\n",
    "0.88 / 0.148 : 0.0157\n",
    "\n",
    "1ere fois\n",
    "je tente 300 et gamma = 0.0156 : [0.8348740349451442, 0.780607476635514]\n",
    "je tente 300 et gamma = 0.0157 :  [0.08033946251768034, 0.16027061705354018]\n",
    "2eme fois idem \n",
    "[0.9062474603819586, 0.8959162941893539]\n",
    "[0.027809965237543453, 0.1580936729663106]\n",
    "3eme fois\n",
    "[0.8829744006501422, 0.12064201544087769]\n",
    "[0.10683826949914715, 0.1655355903447212]\n",
    "\n",
    "\n",
    "gammas = np.linspace(0.01455,0.01655,N)\n",
    " 9 au cas ou 0.015392105263157894\n",
    " 10 0.74 / 0.195 : 0.015497368421052631\n",
    " 11 0.87 / 0.20  : 0.015602631578947368 \n",
    " 12 au cas ou : 0.015707894736842105\n",
    "il devrait exister un \n",
    "\n",
    "0.86 / 0.22 mais jsp quelle valeurs \n",
    "\n",
    "Visiblement rester a des chiffres exacts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[0.9109101991060544, 0.8207029662738724, 0.9089800893945551, 0.9085331166192605, 0.9055160503860219, 0.6329642421779764, 0.9071820398212109, 0.9067249085737505, 0.13592035757822024, 0.13160300690776108, 0.9076696464851687, 0.9055160503860219, 0.7161722876879317, 0.7563490451036164, 0.9104937017472572, 0.9076594880130029, 0.09873019097927671, 0.22479683055668429, 0.6392929703372613, 0.9107273466070703, 0.8376980902072328, 0.09902478667208452, 0.31964648516863065, 0.0904611946363267]\n",
    "[0.00022799817601459188, 0.09291807996710864, 0.03135135135135135, 0.006838738142510479, 0.02413178050571818, 0.21964968359214704, 0.025594539831502613, 0.047312720481427685, 0.15646879152700371, 0.16390364132507848, 0.052735799895779055, 0.054103528933184174, 0.1750324790362584, 0.19310344827586207, 0.0036186814429492254, 0.018570503131073203, 0.163112071161084, 0.1593575465150864, 0.12429712932820361, 0.00022753128555176336, 0.0610049955921246, 0.16367751060820368, 0.1621756861567715, 0.1635135513887721]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.910930516050386, 0.910930516050386, 0.9099756196668021, 0.8630434782608696, 0.6709670865501829, 0.2854937017472572, 0.5486286062576189, 0.9109203575782202, 0.9109203575782202, 0.910930516050386, 0.9095184884193417, 0.9108187728565623, 0.910930516050386, 0.910930516050386, 0.09434173100365705, 0.910930516050386, 0.08906948394961398, 0.08906948394961398, 0.08907964242177976, 0.08906948394961398]\n",
      "[0.0, 0.0, 0.022501654533421574, 0.21970135432341706, 0.1793767418292374, 0.14222298104831826, 0.13871174087499272, 0.0, 0.0, 0.0, 0.0017931189061974671, 0.0, 0.0, 0.0, 0.1627018041454962, 0.0, 0.16356988284456384, 0.16356988284456384, 0.16357140858339475, 0.16356988284456384]\n"
     ]
    }
   ],
   "source": [
    "# Previous Test cant remember param gamma rip for the 0.86 : 0.22\n",
    "print(accs)\n",
    "print(f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tu peux plot tes tableaux ici ca fait ton parametre x accuracies et f1 \n",
    "# (change le gammas si t'as changé de param la haut)\n",
    "plt.plot(degree,accs,\"r\")\n",
    "plt.plot(degree, f1s, \"b\")\n",
    "\n",
    "plt.title(\"ridge regression\")\n",
    "plt.legend([\"accuracy\", \"f1\"])\n",
    "plt.xlabel(\"degrees\")\n",
    "plt.ylabel(\"Accuracy and F1 (%)\")\n",
    "#plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8917005282405526\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2413719490500249"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(accs[15])\n",
    "f1s[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing which method is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy ridge:\n",
      "0.9063693620479479\n",
      "f1 ridge:\n",
      "0.19382489285401908\n",
      "accuracy mse gd:\n",
      "0.910930516050386\n",
      "f1 mse gd:\n",
      "0.0\n",
      "accuracy mse sgd:\n",
      "0.8993295408370581\n",
      "f1 mse sgd:\n",
      "0.15385928961748635\n",
      "accuracy least squares:\n",
      "0.910930516050386\n",
      "f1 mse least squares:\n",
      "0.0\n",
      "accuracy logistic reg:\n",
      "0.910930516050386\n",
      "f1 mse logistic reg:\n",
      "0.0\n",
      "accuracy reg logistic reg:\n",
      "0.910930516050386\n",
      "f1 mse reg logistic reg:\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "gamma = 0.01\n",
    "lambda_ = 0.0000001\n",
    "max_iters = 1000\n",
    "degree = 9\n",
    "initial_w = np.zeros(cleaned_x_train_1.shape[1])\n",
    "\n",
    "# ridge\n",
    "poly_train = build_poly(cleaned_x_train_1, degree)\n",
    "w, loss = ridge_regression(y_train_1, poly_train, lambda_)\n",
    "poly_test = build_poly(cleaned_x_test_1, degree)\n",
    "yp = predict_labels_mse(w, poly_test)\n",
    "\n",
    "print(\"accuracy ridge:\")\n",
    "accuracy = measure_accuracy(y_test_1, yp)\n",
    "print(accuracy)\n",
    "print(\"f1 ridge:\")\n",
    "f1 = measure_f1_score(y_test_1, yp)\n",
    "print(f1)\n",
    "\n",
    "# mse gd\n",
    "w, loss = mean_squared_error_gd(y_train_1, cleaned_x_train_1, initial_w, max_iters, gamma)\n",
    "yp = predict_labels_mse(w, cleaned_x_test_1)\n",
    "\n",
    "print(\"accuracy mse gd:\")\n",
    "accuracy = measure_accuracy(y_test_1, yp)\n",
    "print(accuracy)\n",
    "print(\"f1 mse gd:\")\n",
    "f1 = measure_f1_score(y_test_1, yp)\n",
    "print(f1)\n",
    "\n",
    "# mse sgd\n",
    "w, loss = mean_squared_error_sgd(y_train_1, cleaned_x_train_1, initial_w, max_iters, gamma)\n",
    "yp = predict_labels_mse(w, cleaned_x_test_1)\n",
    "\n",
    "print(\"accuracy mse sgd:\")\n",
    "accuracy = measure_accuracy(y_test_1, yp)\n",
    "print(accuracy)\n",
    "print(\"f1 mse sgd:\")\n",
    "f1 = measure_f1_score(y_test_1, yp)\n",
    "print(f1)\n",
    "\n",
    "# mse sgd\n",
    "w, loss = least_squares(y_train_1, cleaned_x_train_1)\n",
    "yp = predict_labels_mse(w, cleaned_x_test_1)\n",
    "\n",
    "print(\"accuracy least squares:\")\n",
    "accuracy = measure_accuracy(y_test_1, yp)\n",
    "print(accuracy)\n",
    "print(\"f1 mse least squares:\")\n",
    "f1 = measure_f1_score(y_test_1, yp)\n",
    "print(f1)\n",
    "\n",
    "# logistic reg\n",
    "w, loss = logistic_regression(y_train_1, cleaned_x_train_1, initial_w, max_iters, gamma)\n",
    "yp = predict_labels_logistic(w, cleaned_x_test_1)\n",
    "\n",
    "print(\"accuracy logistic reg:\")\n",
    "accuracy = measure_accuracy(y_test_1, yp)\n",
    "print(accuracy)\n",
    "print(\"f1 mse logistic reg:\")\n",
    "f1 = measure_f1_score(y_test_1, yp)\n",
    "print(f1)\n",
    "\n",
    "#  reg logistic reg\n",
    "w, loss = reg_logistic_regression(y_train_1, cleaned_x_train_1, lambda_, initial_w, max_iters, gamma)\n",
    "yp = predict_labels_logistic(w, cleaned_x_test_1)\n",
    "\n",
    "print(\"accuracy reg logistic reg:\")\n",
    "accuracy = measure_accuracy(y_test_1, yp)\n",
    "print(accuracy)\n",
    "print(\"f1 mse reg logistic reg:\")\n",
    "f1 = measure_f1_score(y_test_1, yp)\n",
    "print(f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamdas = 0.0000001\n",
    "accs = []\n",
    "f1s = []\n",
    "degrees = range(25)\n",
    "for deg in degrees:\n",
    "\n",
    "    # ridge\n",
    "    poly_train = build_poly(cleaned_x_train_1, deg)\n",
    "    w, loss = ridge_regression(y_train_1, poly_train, lamdas)\n",
    "    poly_test = build_poly(cleaned_x_test_1, deg)\n",
    "    yp = predict_labels_mse(w, poly_test)\n",
    "\n",
    "    accuracy = measure_accuracy(y_test_1, yp)\n",
    "    f1 = measure_f1_score(y_test_1, yp)\n",
    "    accs.append(accuracy)\n",
    "    f1s.append(f1)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
