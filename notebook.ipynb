{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import *\n",
    "from implementations import *\n",
    "\n",
    "# from test_utils import test\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run de A a Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading  data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, train_ids, test_ids = load_csv_data(\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.genfromtxt(\"dataset/x_test.csv\", delimiter=\",\", dtype = str, max_rows=1)\n",
    "labels = np.delete(labels,0) # delete the label 'id' as we dont have it in x_train and x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the high number of features with all different exceptions values and linearity, we decided to select manually the features we found relevant. The list below is the name of the feature, the exception values that we have to remplace, and wheter we remplace by majority (True) or by the mean (False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = [(\"MSCODE\", [], True, None),\n",
    "            (\"_HCVU651\", [9], True, None),\n",
    "            (\"_RFHYPE5\", [9], True, None),\n",
    "            (\"_RFCHOL\", [9], True, None),\n",
    "            (\"_RACE\",[9], True, None),\n",
    "            (\"_BMI5\",[], False, None),\n",
    "            (\"_EDUCAG\",[9], True, None),\n",
    "            (\"_INCOMG\",[9], True, None),\n",
    "            (\"_DRNKWEK\",[99900], False, None),\n",
    "            (\"_SMOKER3\",[9], True, None),\n",
    "            (\"_FRUTSUM\",[], False, None),\n",
    "            (\"_VEGESUM\",[], False, None),\n",
    "            (\"PA1MIN_\",[], False, None),\n",
    "            (\"GENHLTH\",[7,9], False, None),\n",
    "            (\"CHECKUP1\",[7,9], False, None),\n",
    "            (\"MENTHLTH\",[77, 99], False, 88), \n",
    "            (\"BPHIGH4\",[7,9], True, None),\n",
    "            (\"BPMEDS\",[7,9], True, None),\n",
    "            (\"TOLDHI2\",[7,9], True, None),\n",
    "            (\"CHCOCNCR\",[7,8,9], True, None),\n",
    "            (\"DIABETE3\",[7,8,9], True, None),\n",
    "            (\"SEX\",[], True, None),\n",
    "            (\"QLACTLM2\",[7,9], True, None),\n",
    "            (\"AVEDRNK2\",[77, 99], False, None),\n",
    "            (\"EXERANY2\",[7,9], True, None),\n",
    "            (\"SHINGLE2\", [7,9], True, None),\n",
    "            (\"LMTJOIN3\", [7,9], True, None),\n",
    "            (\"CVDASPRN\", [7,9], True, None),\n",
    "            (\"PHYSHLTH\",[77,99], False, 88), #88 -> 0 \n",
    "            (\"POORHLTH\",[77,99], False, 88), # 88 -> 0  \n",
    "            (\"HLTHPLN1\",[7,9], True, None),\n",
    "            (\"BLOODCHO\", [7,9], True, None),\n",
    "            (\"CHOLCHK\",[7,9],True, None),\n",
    "            (\"CVDSTRK3\", [7,9], True, None),\n",
    "            (\"ASTHMA3\", [7,9], True, None),\n",
    "            (\"ASTHNOW\", [7,9], True, None),\n",
    "            (\"CHCSCNCR\", [7,9], True, None),\n",
    "            (\"CHCCOPD1\",[7,9], True, None),\n",
    "            (\"HAVARTH3\", [7,9], True, None),\n",
    "            (\"ADDEPEV2\", [7,9], True, None),\n",
    "            (\"CHCKIDNY\", [7,9], True, None),\n",
    "            (\"DIABAGE2\", [98,99], False, None),\n",
    "            (\"MARITAL\", [9], True, None),\n",
    "            (\"RENTHOM1\", [7,9], True, None),\n",
    "            (\"EMPLOY1\", [9], True, None),\n",
    "            (\"CHILDREN\", [99], False, 88), # 88 -> 0 \n",
    "            (\"INCOME2\", [77,99], True, None),\n",
    "            (\"INTERNET\", [7,9], True, None),\n",
    "            (\"QLACTLM2\", [7,9], True, None),\n",
    "            (\"USEEQUIP\", [7,9], True, None),\n",
    "            (\"BLIND\", [7,9], True, None),\n",
    "            (\"DECIDE\", [7,9], True, None),\n",
    "            (\"DIFFWALK\", [7,9], True, None),\n",
    "            (\"DIFFDRES\", [7,9], True, None),\n",
    "            (\"DIFFALON\", [7,9], True, None),\n",
    "            (\"SMOKE100\", [7,9], True, None),\n",
    "            (\"SMOKDAY2\", [7,9], True, None),\n",
    "            (\"STOPSMK2\", [7,9], True, None),\n",
    "            (\"USENOW3\", [7,9], True, None), \n",
    "            (\"DRNK3GE5\", [77,99],False, 88),\n",
    "            (\"MAXDRNKS\", [77,99], False, None),\n",
    "            (\"LMTJOIN3\", [7,9], True, None),\n",
    "            (\"ARTHDIS2\", [7,9], True, None),\n",
    "            (\"ARTHSOCL\", [7,9], True,None),\n",
    "            (\"FLUSHOT6\", [7,9],True, None),\n",
    "            (\"PNEUVAC3\", [7,9], True, None),\n",
    "            (\"PDIABTST\", [7,9], True,None),\n",
    "            (\"_RFHLTH\", [9], True, None),\n",
    "            (\"_CHOLCHK\", [9], True, None),\n",
    "            (\"_LTASTH1\", [9], True,None),\n",
    "            (\"_CASTHM1\", [9], True, None),\n",
    "            (\"_DRDXAR1\", [], True, None),\n",
    "            (\"WTKG3\", [99999], False , None),\n",
    "            (\"_RFBMI5\", [9], True, None),\n",
    "            (\"_RFSMOK3\", [9], True , None),\n",
    "            (\"DRNKANY5\", [7,9], True, None),\n",
    "            (\"DROCDY3_\", [900], False,None),\n",
    "            (\"_RFBING5\", [9], True, None),\n",
    "            (\"FTJUDA1_\", [], False, None),\n",
    "            (\"FRUTDA1_\", [], False, None),\n",
    "            (\"BEANDAY_\", [], False, None),\n",
    "            (\"GRENDAY_\",[], False,None),\n",
    "            (\"ORNGDAY_\", [],False, None),\n",
    "            (\"VEGEDA1_\", [], False, None),\n",
    "            ]\n",
    "\n",
    "cleaned_x_train = clean_data(labels, label_list, x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328135, 84)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then check that we have enough data in our features, i.e. there is not an exagerated amount of nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# want to see which labels are way to small\n",
    "\n",
    "for label in label_list:\n",
    "    l, _, _ = label\n",
    "    id = np.where(labels == l)[0][0]\n",
    "    x = x_train[:][id]\n",
    "\n",
    "    # Count the number of NaN values\n",
    "    nans= np.count_nonzero(np.isnan(x))\n",
    "    nan_perc = nans/len(x) *100\n",
    "    #print(nan_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check that our features are uncorrelated as it would lead to less good results, but we saw that the uncorrelated data had the same dimension as the original cleaned data, so no changes were made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328135, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(328135, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_matrix = np.corrcoef(cleaned_x_train, rowvar=False)\n",
    "correlation_threshold = 0.7\n",
    "uncorrelated_indices = np.where(np.abs(correlation_matrix) < correlation_threshold)\n",
    "uncorrelated_columns = np.unique(uncorrelated_indices[1])\n",
    "uncorrelated_data = cleaned_x_train[:, uncorrelated_columns]\n",
    "print(uncorrelated_data.shape)\n",
    "cleaned_x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "We here choose which function we want to train our data with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(701,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_ = 0.0001\n",
    "degree = 25\n",
    "## tx is cleaned data \n",
    "poly = build_poly(cleaned_x_train,degree)\n",
    "w , loss = ridge_regression(y_train,poly,lambda_)\n",
    "w.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean squared errors gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.0001\n",
    "max_iters = 1000\n",
    "w_initial = np.zeros(cleaned_x_train.shape[1])\n",
    "\n",
    "w, loss = mean_squared_error_gd(y_train, cleaned_x_train, w_initial, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15174410864282326"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean squared error sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_1, y_train_1, x_test_1, y_test_1 = split_train_test(y_train, x_train, 0.7)\n",
    "cleaned_x_train_1 = clean_data(labels, label_list, x_train_1)\n",
    "cleaned_x_test_1 = clean_data(labels, label_list, x_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y pred : '[4.37600356e+25 5.52661106e+25 4.51852034e+25 ... 3.91049147e+25\n",
      " 5.08228170e+25 5.06617256e+25]'.\n"
     ]
    }
   ],
   "source": [
    "x_train_1, y_train_1, x_test_1, y_test_1 = split_train_test(y_train, x_train, 0.7)\n",
    "cleaned_x_train_1 = clean_data(labels, label_list, x_train_1)\n",
    "cleaned_x_test_1 = clean_data(labels, label_list, x_test_1)\n",
    "\n",
    "gamma = 0.03684211157894737\n",
    "max_iters = 300\n",
    "#w_initial = np.zeros(cleaned_x_train.shape[1])\n",
    "initial_w = np.zeros(cleaned_x_train_1.shape[1])\n",
    "# remettre a 0 entre chaque run ? \n",
    "w = []\n",
    "loss = 0\n",
    "yp = []\n",
    "acc = 0\n",
    "f1 = 0\n",
    "\n",
    "#w, loss = mean_squared_error_sgd(y_train, cleaned_x_train, w_initial, max_iters, gamma)\n",
    "w, loss = mean_squared_error_gd(y_train_1, cleaned_x_train_1, initial_w, max_iters, gamma)\n",
    "yp = predict_labels_mse(w,cleaned_x_test_1)\n",
    "#yp = predict_labels_logistic(w, cleaned_x_test_1)\n",
    "\n",
    "# mesure accuracy\n",
    "acc = measure_accuracy(y_test_1, yp)\n",
    "f1 = measure_f1_score(y_test_1, yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16356988284456384"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.00360482144868762"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Least squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, loss = least_squares(y_train, cleaned_x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\duval\\Documents\\GitHub\\ML_project1\\helpers.py:96: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0 / (1 + np.exp(-t))\n",
      "c:\\Users\\duval\\Documents\\GitHub\\ML_project1\\helpers.py:115: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -np.mean(y * np.log(pred) + (1 - y) * np.log(1 - pred))\n",
      "c:\\Users\\duval\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\_methods.py:180: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n"
     ]
    }
   ],
   "source": [
    "max_iters = 1000\n",
    "gamma = 0.01\n",
    "w_initial = np.zeros(cleaned_x_train.shape[1])\n",
    "w, loss = logistic_regression(y_train, cleaned_x_train, w_initial, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reg logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iters = 1000\n",
    "gamma = 0.01\n",
    "lambda_ = 0.001\n",
    "w_initial = np.zeros(cleaned_x_train.shape[1])\n",
    "w, loss = reg_logistic_regression(y_train, cleaned_x_train, lambda_, w_initial, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(w)\n",
    "#print(loss)\n",
    "#print(len(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "\n",
    "We then test our data, cleaning the test dataset and building predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up x test\n",
    "\n",
    "cleaned_x_test = clean_data(labels, label_list, x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109379, 701)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only used for ridge\n",
    "poly_test = build_poly(cleaned_x_test,degree)\n",
    "poly_test.shape                                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction\n",
    "\n",
    "Use the correct prediction function depending on which train method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp = predict_labels_mse(w,cleaned_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00000000e+000 0.00000000e+000 0.00000000e+000 ... 1.19096188e-304\n",
      " 0.00000000e+000 0.00000000e+000]\n"
     ]
    }
   ],
   "source": [
    "yp = predict_labels_logistic(w,cleaned_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(np.where(y_pred == 1)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSV Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_submission(test_ids,yp,\"outputs/ridge_degre25_200features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split for our own cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####read me or smth\n",
    "\n",
    "- N c'est le nombre de loops\n",
    "- pour l'instant ca loop sur gamma mais si tu veux changer de param tu peux le modifier\n",
    "- initial_w, accs et f1s pas besoin de changer\n",
    "\n",
    "Utilise pas ridge i guess tfacon c'est pas celle qui nous interesse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_1, y_train_1, x_test_1, y_test_1 = split_train_test(y_train, x_train, 0.6)\n",
    "cleaned_x_train_1 = clean_data(labels, label_list, x_train_1)\n",
    "cleaned_x_test_1 = clean_data(labels, label_list, x_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y pred : '[-3.86836112 -0.9438371  -0.79778624 ...  0.03453413 -1.09315406\n",
      " -0.52677595]'.\n",
      "y pred : '[ 3.12567177  0.67683337 -1.92261164 ...  1.14480517 -1.81145354\n",
      "  0.94434354]'.\n",
      "y pred : '[-0.26232482 -0.73475675 -0.90690548 ...  0.11605854 -0.94849401\n",
      " -0.86210978]'.\n",
      "y pred : '[-0.25933356 -0.83140562 -0.81753155 ... -0.07188808 -0.89737581\n",
      " -0.819845  ]'.\n",
      "y pred : '[-0.11827825 -0.86365607 -0.75827577 ... -0.17233343 -0.87557772\n",
      " -0.61436494]'.\n",
      "y pred : '[ 0.13882423 -0.87209227 -0.68717902 ... -0.19358449 -0.82858333\n",
      " -0.15938601]'.\n",
      "y pred : '[ 0.85394071 -0.76154504 -0.54089667 ... -0.06854787 -0.59301626\n",
      "  1.53466113]'.\n",
      "y pred : '[-17.95157929  -4.57424725  -3.78249634 ...  -5.64871935  -6.57051798\n",
      " -44.04061927]'.\n",
      "y pred : '[-2.47504841 -1.67346299 -1.00597671 ... -1.1244175  -1.59373554\n",
      " -6.70358822]'.\n",
      "y pred : '[-1.65241389 -1.59475957 -0.83354371 ... -0.95443338 -1.35162783\n",
      " -4.86656789]'.\n"
     ]
    }
   ],
   "source": [
    "N = 10\n",
    "max_iters = 300\n",
    "\n",
    "gammas = np.linspace(0.00000001, 0.1, N)\n",
    "#gammas = [0.018,0.185,0.019,0.0195,0.020]\n",
    "#degree = range(25)\n",
    "degree = 14\n",
    "#gammas = np.linspace(0.01,0.001,N)\n",
    "#gammas = np.linspace(0.00001, 0.1, N)\n",
    "\n",
    "#lambda_ = 0.01\n",
    "lambda_ = np.linspace(0.0001, 0.1, N)\n",
    "\n",
    "initial_w = np.zeros(cleaned_x_train_1.shape[1])\n",
    "accs6 = []\n",
    "f1s6 = []\n",
    "\n",
    "for lam in lambda_:\n",
    "    #print(\"Gamma : '{}'.\".format(gamma))\n",
    "    # train\n",
    "    # choisi la methode de train qui t'interesse\n",
    "    poly_train = build_poly(cleaned_x_train_1, degree)\n",
    "    w, loss = ridge_regression(y_train_1, poly_train, lam)\n",
    "    #w, loss = mean_squared_error_gd(y_train_1, cleaned_x_train_1, initial_w, max_iters, gamma)\n",
    "    ## remplacer gamma par lambda \n",
    "    #w, loss = reg_logistic_regression(y_train_1, cleaned_x_train_1, lambda_, initial_w, max_iters, gamma)\n",
    "    #predict \n",
    "    # choisi la methode de test qui t'interresse (commente l'autre)\n",
    "    poly_test = build_poly(cleaned_x_test_1, degree)\n",
    "    yp = predict_labels_mse(w,poly_test)\n",
    "    #yp = predict_labels_logistic(w, cleaned_x_test_1)\n",
    "\n",
    "    # mesure accuracy\n",
    "    acc = measure_accuracy(y_test_1, yp)\n",
    "    f1 = measure_f1_score(y_test_1, yp)\n",
    "    accs6.append(acc)\n",
    "    f1s6.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7411179579074403, 0.8560527101732829, 0.6801306783204423, 0.8439722796174733, 0.7809187709899005, 0.7496815325446311, 0.856826784179634, 0.872460641079559, 0.8727044439162049, 0.5850841424539974, 0.8425419415789233, 0.6296036692215095, 0.8349612202294787, 0.8712344004754141, 0.879782711384034, 0.8572005424596584, 0.7642205189937069, 0.5425129900803023, 0.6192725555030704, 0.6494202081460374]\n",
      "[0.19462247335886837, 0.25065837484532155, 0.12431169697980977, 0.22335487394193138, 0.2084562871614182, 0.1424842878917587, 0.14469851441887563, 0.13120199294166493, 0.1327187409160749, 0.18680714831804282, 0.1899423823148983, 0.14154541601921175, 0.10753131179960448, 0.11080128373757037, 0.14592692828146142, 0.18184992797590466, 0.17194231129424986, 0.16458672454331705, 0.16771593218080677, 0.16962916177930162]\n"
     ]
    }
   ],
   "source": [
    "# pour 0.5\n",
    "print(accs)\n",
    "print(f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8425419415789233, 0.6296036692215095, 0.8349612202294787, 0.8712344004754141, 0.879782711384034, 0.8572005424596584, 0.7642205189937069, 0.5425129900803023, 0.6192725555030704, 0.6494202081460374]\n",
      "[0.1899423823148983, 0.14154541601921175, 0.10753131179960448, 0.11080128373757037, 0.14592692828146142, 0.18184992797590466, 0.17194231129424986, 0.16458672454331705, 0.16771593218080677, 0.16962916177930162]\n"
     ]
    }
   ],
   "source": [
    "print(accs6)\n",
    "print(f1s6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accs7)\n",
    "print(f1s7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08900000000000001"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_ = np.linspace(0.001, 0.1, N)\n",
    "lambda_[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of elements above the threshold:  [10, 11]\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.19\n",
    "# Get the indices where values are greater than the threshold\n",
    "indices_above_threshold = [i for i, value in enumerate(f1s) if value > threshold]\n",
    "\n",
    "# Sort the indices\n",
    "indices_above_threshold.sort()\n",
    "\n",
    "print(\"Indices of elements above the threshold: \", indices_above_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.63 / 0.219 : entre 0.0156 et 0.0159 \n",
    "0.837 : 0.153 : 0.0156\n",
    "0.88 / 0.148 : 0.0157\n",
    "\n",
    "1ere fois\n",
    "je tente 300 et gamma = 0.0156 : [0.8348740349451442, 0.780607476635514]\n",
    "je tente 300 et gamma = 0.0157 :  [0.08033946251768034, 0.16027061705354018]\n",
    "2eme fois idem \n",
    "[0.9062474603819586, 0.8959162941893539]\n",
    "[0.027809965237543453, 0.1580936729663106]\n",
    "3eme fois\n",
    "[0.8829744006501422, 0.12064201544087769]\n",
    "[0.10683826949914715, 0.1655355903447212]\n",
    "\n",
    "\n",
    "gammas = np.linspace(0.01455,0.01655,N)\n",
    " 9 au cas ou 0.015392105263157894\n",
    " 10 0.74 / 0.195 : 0.015497368421052631\n",
    " 11 0.87 / 0.20  : 0.015602631578947368 \n",
    " 12 au cas ou : 0.015707894736842105\n",
    "il devrait exister un \n",
    "\n",
    "0.86 / 0.22 mais jsp quelle valeurs \n",
    "\n",
    "Visiblement rester a des chiffres exacts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[0.9109101991060544, 0.8207029662738724, 0.9089800893945551, 0.9085331166192605, 0.9055160503860219, 0.6329642421779764, 0.9071820398212109, 0.9067249085737505, 0.13592035757822024, 0.13160300690776108, 0.9076696464851687, 0.9055160503860219, 0.7161722876879317, 0.7563490451036164, 0.9104937017472572, 0.9076594880130029, 0.09873019097927671, 0.22479683055668429, 0.6392929703372613, 0.9107273466070703, 0.8376980902072328, 0.09902478667208452, 0.31964648516863065, 0.0904611946363267]\n",
    "[0.00022799817601459188, 0.09291807996710864, 0.03135135135135135, 0.006838738142510479, 0.02413178050571818, 0.21964968359214704, 0.025594539831502613, 0.047312720481427685, 0.15646879152700371, 0.16390364132507848, 0.052735799895779055, 0.054103528933184174, 0.1750324790362584, 0.19310344827586207, 0.0036186814429492254, 0.018570503131073203, 0.163112071161084, 0.1593575465150864, 0.12429712932820361, 0.00022753128555176336, 0.0610049955921246, 0.16367751060820368, 0.1621756861567715, 0.1635135513887721]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.910930516050386, 0.910930516050386, 0.9099756196668021, 0.8630434782608696, 0.6709670865501829, 0.2854937017472572, 0.5486286062576189, 0.9109203575782202, 0.9109203575782202, 0.910930516050386, 0.9095184884193417, 0.9108187728565623, 0.910930516050386, 0.910930516050386, 0.09434173100365705, 0.910930516050386, 0.08906948394961398, 0.08906948394961398, 0.08907964242177976, 0.08906948394961398]\n",
      "[0.0, 0.0, 0.022501654533421574, 0.21970135432341706, 0.1793767418292374, 0.14222298104831826, 0.13871174087499272, 0.0, 0.0, 0.0, 0.0017931189061974671, 0.0, 0.0, 0.0, 0.1627018041454962, 0.0, 0.16356988284456384, 0.16356988284456384, 0.16357140858339475, 0.16356988284456384]\n"
     ]
    }
   ],
   "source": [
    "# Previous Test cant remember param gamma rip for the 0.86 : 0.22\n",
    "print(accs)\n",
    "print(f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tu peux plot tes tableaux ici ca fait ton parametre x accuracies et f1 \n",
    "# (change le gammas si t'as chang√© de param la haut)\n",
    "plt.plot(lambda_,accs,\"r\")\n",
    "plt.plot(lambda_, f1s, \"b\")\n",
    "plt.plot(lambda_,accs6,\"g\")\n",
    "plt.plot(lambda_, f1s6, \"y\")\n",
    "plt.plot(lambda_,accs7,\"o\")\n",
    "plt.plot(lambda_, f1s7, \"p\")\n",
    "\n",
    "plt.title(\"ridge regression\")\n",
    "plt.legend([\"accuracy 0.5\", \"f1 0.5\", \"accuracy 0.6\", \"f1 0.6\", \"accuracy 0.6\", \"f1 0.6\"])\n",
    "plt.xlabel(\"lambda\")\n",
    "plt.ylabel(\"Accuracy and F1 (%)\")\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0001 0.0112 0.0223 0.0334 0.0445 0.0556 0.0667 0.0778 0.0889 0.1   ]\n"
     ]
    }
   ],
   "source": [
    "print(lambda_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.872460641079559\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.25065837484532155"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(accs[7])\n",
    "f1s[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing which method is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy ridge:\n",
      "0.9063693620479479\n",
      "f1 ridge:\n",
      "0.19382489285401908\n",
      "accuracy mse gd:\n",
      "0.910930516050386\n",
      "f1 mse gd:\n",
      "0.0\n",
      "accuracy mse sgd:\n",
      "0.8993295408370581\n",
      "f1 mse sgd:\n",
      "0.15385928961748635\n",
      "accuracy least squares:\n",
      "0.910930516050386\n",
      "f1 mse least squares:\n",
      "0.0\n",
      "accuracy logistic reg:\n",
      "0.910930516050386\n",
      "f1 mse logistic reg:\n",
      "0.0\n",
      "accuracy reg logistic reg:\n",
      "0.910930516050386\n",
      "f1 mse reg logistic reg:\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "gamma = 0.01\n",
    "lambda_ = 0.0000001\n",
    "max_iters = 1000\n",
    "degree = 9\n",
    "initial_w = np.zeros(cleaned_x_train_1.shape[1])\n",
    "\n",
    "# ridge\n",
    "poly_train = build_poly(cleaned_x_train_1, degree)\n",
    "w, loss = ridge_regression(y_train_1, poly_train, lambda_)\n",
    "poly_test = build_poly(cleaned_x_test_1, degree)\n",
    "yp = predict_labels_mse(w, poly_test)\n",
    "\n",
    "print(\"accuracy ridge:\")\n",
    "accuracy = measure_accuracy(y_test_1, yp)\n",
    "print(accuracy)\n",
    "print(\"f1 ridge:\")\n",
    "f1 = measure_f1_score(y_test_1, yp)\n",
    "print(f1)\n",
    "\n",
    "# mse gd\n",
    "w, loss = mean_squared_error_gd(y_train_1, cleaned_x_train_1, initial_w, max_iters, gamma)\n",
    "yp = predict_labels_mse(w, cleaned_x_test_1)\n",
    "\n",
    "print(\"accuracy mse gd:\")\n",
    "accuracy = measure_accuracy(y_test_1, yp)\n",
    "print(accuracy)\n",
    "print(\"f1 mse gd:\")\n",
    "f1 = measure_f1_score(y_test_1, yp)\n",
    "print(f1)\n",
    "\n",
    "# mse sgd\n",
    "w, loss = mean_squared_error_sgd(y_train_1, cleaned_x_train_1, initial_w, max_iters, gamma)\n",
    "yp = predict_labels_mse(w, cleaned_x_test_1)\n",
    "\n",
    "print(\"accuracy mse sgd:\")\n",
    "accuracy = measure_accuracy(y_test_1, yp)\n",
    "print(accuracy)\n",
    "print(\"f1 mse sgd:\")\n",
    "f1 = measure_f1_score(y_test_1, yp)\n",
    "print(f1)\n",
    "\n",
    "# mse sgd\n",
    "w, loss = least_squares(y_train_1, cleaned_x_train_1)\n",
    "yp = predict_labels_mse(w, cleaned_x_test_1)\n",
    "\n",
    "print(\"accuracy least squares:\")\n",
    "accuracy = measure_accuracy(y_test_1, yp)\n",
    "print(accuracy)\n",
    "print(\"f1 mse least squares:\")\n",
    "f1 = measure_f1_score(y_test_1, yp)\n",
    "print(f1)\n",
    "\n",
    "# logistic reg\n",
    "w, loss = logistic_regression(y_train_1, cleaned_x_train_1, initial_w, max_iters, gamma)\n",
    "yp = predict_labels_logistic(w, cleaned_x_test_1)\n",
    "\n",
    "print(\"accuracy logistic reg:\")\n",
    "accuracy = measure_accuracy(y_test_1, yp)\n",
    "print(accuracy)\n",
    "print(\"f1 mse logistic reg:\")\n",
    "f1 = measure_f1_score(y_test_1, yp)\n",
    "print(f1)\n",
    "\n",
    "#  reg logistic reg\n",
    "w, loss = reg_logistic_regression(y_train_1, cleaned_x_train_1, lambda_, initial_w, max_iters, gamma)\n",
    "yp = predict_labels_logistic(w, cleaned_x_test_1)\n",
    "\n",
    "print(\"accuracy reg logistic reg:\")\n",
    "accuracy = measure_accuracy(y_test_1, yp)\n",
    "print(accuracy)\n",
    "print(\"f1 mse reg logistic reg:\")\n",
    "f1 = measure_f1_score(y_test_1, yp)\n",
    "print(f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamdas = 0.0000001\n",
    "accs = []\n",
    "f1s = []\n",
    "degrees = range(25)\n",
    "for deg in degrees:\n",
    "\n",
    "    # ridge\n",
    "    poly_train = build_poly(cleaned_x_train_1, deg)\n",
    "    w, loss = ridge_regression(y_train_1, poly_train, lamdas)\n",
    "    poly_test = build_poly(cleaned_x_test_1, deg)\n",
    "    yp = predict_labels_mse(w, poly_test)\n",
    "\n",
    "    accuracy = measure_accuracy(y_test_1, yp)\n",
    "    f1 = measure_f1_score(y_test_1, yp)\n",
    "    accs.append(accuracy)\n",
    "    f1s.append(f1)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
