{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import *\n",
    "from implementations import *\n",
    "\n",
    "# from test_utils import test\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run de A a Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading  data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, train_ids, test_ids = load_csv_data(\"dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.genfromtxt(\"dataset/x_test.csv\", delimiter=\",\", dtype = str, max_rows=1)\n",
    "labels = np.delete(labels,0) # delete the label 'id' as we dont have it in x_train and x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the high number of features with all different exceptions values and linearity, we decided to select manually the features we found relevant. The list below is the name of the feature, the exception values that we have to remplace, and wheter we remplace by majority (True) or by the mean (False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = [(\"MSCODE\", [], True),\n",
    "            (\"_HCVU651\", [9], True),\n",
    "            (\"_RFHYPE5\", [9], True),\n",
    "            (\"_RFCHOL\", [9], True),\n",
    "            (\"_RACE\",[9], True),\n",
    "            (\"_BMI5\",[], False),\n",
    "            (\"_EDUCAG\",[9], True),\n",
    "            (\"_INCOMG\",[9], True),\n",
    "            (\"_DRNKWEK\",[99900], False),\n",
    "            (\"_SMOKER3\",[9], True),\n",
    "            (\"_FRUTSUM\",[], False),\n",
    "            (\"_VEGESUM\",[], False),\n",
    "            (\"PA1MIN_\",[], False),\n",
    "            #(\"GENHLTH\",[7,9], False),\n",
    "            #(\"CHECKUP1\",[7,9], False),\n",
    "            #(\"MENTHLTH\",[88, 77, 99], False),\n",
    "            #(\"BPHIGH4\",[7,9], True),\n",
    "            #(\"BPMEDS\",[7,9], True),\n",
    "            #(\"TOLDHI2\",[7,9], True),\n",
    "            (\"CHCOCNCR\",[7,8,9], True),\n",
    "            (\"DIABETE3\",[7,8,9], True),\n",
    "            #(\"SEX\",[], True),\n",
    "            #(\"QLACTLM2\",[7,9], True),\n",
    "            #(\"AVEDRNK2\",[77, 99], False),\n",
    "            #(\"EXERANY2\",[7,9], True),\n",
    "            #(\"SHINGLE2\", [7,9], True),\n",
    "            #(\"LMTJOIN3\", [7,9], True),\n",
    "            #(\"CVDASPRN\", [7,9], True)\n",
    "            ]\n",
    "\n",
    "\n",
    "cleaned_x_train = clean_data(labels, label_list, x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,\n",
       "        -4.89451372e-01,  2.00000000e+00,  3.00000000e+00],\n",
       "       [ 5.00000000e+00,  1.00000000e+00,  2.00000000e+00, ...,\n",
       "        -9.33005477e-17,  2.00000000e+00,  3.00000000e+00],\n",
       "       [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,\n",
       "        -6.70001037e-01,  2.00000000e+00,  3.00000000e+00],\n",
       "       ...,\n",
       "       [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,\n",
       "        -6.20760219e-01,  2.00000000e+00,  3.00000000e+00],\n",
       "       [ 5.00000000e+00,  1.00000000e+00,  1.00000000e+00, ...,\n",
       "        -7.71765394e-01,  2.00000000e+00,  3.00000000e+00],\n",
       "       [ 1.00000000e+00,  1.00000000e+00,  2.00000000e+00, ...,\n",
       "        -8.17723491e-01,  2.00000000e+00,  3.00000000e+00]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then check that we have enough data in our features, i.e. there is not an exagerated amount of nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# want to see which labels are way to small\n",
    "\n",
    "for label in label_list:\n",
    "    l, _, _ = label\n",
    "    id = np.where(labels == l)[0][0]\n",
    "    x = x_train[:][id]\n",
    "\n",
    "    # Count the number of NaN values\n",
    "    nans= np.count_nonzero(np.isnan(x))\n",
    "    nan_perc = nans/len(x) *100\n",
    "    #print(nan_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check that our features are uncorrelated as it would lead to less good results, but we saw that the uncorrelated data had the same dimension as the original cleaned data, so no changes were made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328135, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(328135, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_matrix = np.corrcoef(cleaned_x_train, rowvar=False)\n",
    "correlation_threshold = 0.7\n",
    "uncorrelated_indices = np.where(np.abs(correlation_matrix) < correlation_threshold)\n",
    "uncorrelated_columns = np.unique(uncorrelated_indices[1])\n",
    "uncorrelated_data = cleaned_x_train[:, uncorrelated_columns]\n",
    "print(uncorrelated_data.shape)\n",
    "cleaned_x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "We here choose which function we want to train our data with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(701,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_ = 0.0001\n",
    "degree = 25\n",
    "## tx is cleaned data \n",
    "poly = build_poly(cleaned_x_train,degree)\n",
    "w , loss = ridge_regression(y_train,poly,lambda_)\n",
    "w.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean squared errors gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.0001\n",
    "max_iters = 1000\n",
    "w_initial = np.zeros(cleaned_x_train.shape[1])\n",
    "\n",
    "w, loss = mean_squared_error_gd(y_train, cleaned_x_train, w_initial, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15174410864282326"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean squared error sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.00001\n",
    "max_iters = 100\n",
    "w_initial = np.zeros(cleaned_x_train.shape[1])\n",
    "\n",
    "w, loss = mean_squared_error_sgd(y_train, cleaned_x_train, w_initial, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Least squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, loss = least_squares(y_train, cleaned_x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\duval\\Documents\\GitHub\\ML_project1\\helpers.py:96: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0 / (1 + np.exp(-t))\n",
      "c:\\Users\\duval\\Documents\\GitHub\\ML_project1\\helpers.py:115: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -np.mean(y * np.log(pred) + (1 - y) * np.log(1 - pred))\n",
      "c:\\Users\\duval\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\_methods.py:180: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n"
     ]
    }
   ],
   "source": [
    "max_iters = 1000\n",
    "gamma = 0.01\n",
    "w_initial = np.zeros(cleaned_x_train.shape[1])\n",
    "w, loss = logistic_regression(y_train, cleaned_x_train, w_initial, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reg logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iters = 1000\n",
    "gamma = 0.01\n",
    "lambda_ = 0.001\n",
    "w_initial = np.zeros(cleaned_x_train.shape[1])\n",
    "w, loss = reg_logistic_regression(y_train, cleaned_x_train, lambda_, w_initial, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(w)\n",
    "#print(loss)\n",
    "#print(len(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "\n",
    "We then test our data, cleaning the test dataset and building predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up x test\n",
    "\n",
    "cleaned_x_test = clean_data(labels, label_list, x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109379, 701)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only used for ridge\n",
    "poly_test = build_poly(cleaned_x_test,degree)\n",
    "poly_test.shape\n",
    "                                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction\n",
    "\n",
    "Use the correct prediction function depending on which train method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp = predict_labels_mse(w,cleaned_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00000000e+000 0.00000000e+000 0.00000000e+000 ... 1.19096188e-304\n",
      " 0.00000000e+000 0.00000000e+000]\n"
     ]
    }
   ],
   "source": [
    "yp = predict_labels_logistic(w,cleaned_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(np.where(y_pred == 1)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSV Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_submission(test_ids,yp,\"outputs/ridge_degre25_200features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split for our own cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####read me or smth\n",
    "\n",
    "- N c'est le nombre de loops\n",
    "- pour l'instant ca loop sur gamma mais si tu veux changer de param tu peux le modifier\n",
    "- initial_w, accs et f1s pas besoin de changer\n",
    "\n",
    "Utilise pas ridge i guess tfacon c'est pas celle qui nous interesse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_1, y_train_1, x_test_1, y_test_1 = split_train_test(y_train, x_train, 0.7)\n",
    "cleaned_x_train_1 = clean_data(labels, label_list, x_train_1)\n",
    "cleaned_x_test_1 = clean_data(labels, label_list, x_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gammas : '0.01555'.\n",
      "y pred : '[-12.65265487 -15.64788083  -0.97244884 ... -14.40771769 -16.41392299\n",
      " -19.04338792]'.\n",
      "Gammas : '0.015661111111111112'.\n",
      "y pred : '[-0.18800594  0.0521824   0.49063192 ...  0.30895106  0.081623\n",
      " -0.1533118 ]'.\n",
      "Gammas : '0.015772222222222222'.\n",
      "y pred : '[-2.17944471 -2.4040565  -2.1568758  ... -1.80572702 -2.47722675\n",
      " -2.01770134]'.\n",
      "Gammas : '0.015883333333333333'.\n",
      "y pred : '[-1.04169984 -1.19910456 -0.97668698 ... -0.95966625 -1.07760354\n",
      " -1.07815049]'.\n",
      "Gammas : '0.015994444444444443'.\n",
      "y pred : '[-1.28607275 -1.32260811 -0.81223492 ... -1.22834892 -1.1950356\n",
      " -1.10568079]'.\n",
      "Gammas : '0.016105555555555554'.\n",
      "y pred : '[-0.44025471 -1.34265706 -0.24094104 ... -1.35005886 -1.37318831\n",
      " -0.96510149]'.\n",
      "Gammas : '0.016216666666666664'.\n",
      "y pred : '[-2.56512982 -1.42529424 -2.5942495  ... -2.68869876 -1.6704096\n",
      " -0.8751916 ]'.\n",
      "Gammas : '0.016327777777777778'.\n",
      "y pred : '[-0.57586797 -0.97199187 -0.04830943 ... -1.10862397 -0.82716291\n",
      " -1.42782464]'.\n",
      "Gammas : '0.01643888888888889'.\n",
      "y pred : '[-0.55545051 -1.50949479 -1.00294112 ... -0.64788747 -1.6097533\n",
      " -0.75406422]'.\n",
      "Gammas : '0.01655'.\n",
      "y pred : '[-0.52280295 -0.27308733 -0.44479334 ... -0.47248915 -0.30885761\n",
      " -1.35897146]'.\n"
     ]
    }
   ],
   "source": [
    "N = 20\n",
    "max_iters = 300\n",
    "\n",
    "#gammas = np.linspace(0.00000001, 0.1, N)\n",
    "#gammas = [0.018,0.185,0.019,0.0195,0.020]\n",
    "gammas = np.linspace(0.01555,0.01655,10)\n",
    "\n",
    "lambda_ = 0.01\n",
    "#lambda_ = np.linspace(0.000001, 0.1, N)\n",
    "\n",
    "initial_w = np.zeros(cleaned_x_train_1.shape[1])\n",
    "accs = []\n",
    "f1s = []\n",
    "\n",
    "for gamma in gammas:\n",
    "    print(\"Gammas : '{}'.\".format(gamma))\n",
    "    # train\n",
    "    # choisi la methode de train qui t'interesse\n",
    "    w, loss = mean_squared_error_sgd(y_train_1, cleaned_x_train_1, initial_w, max_iters, gamma)\n",
    "    ## remplacer gamma par lambda \n",
    "    #w, loss = reg_logistic_regression(y_train_1, cleaned_x_train_1, lambda_, initial_w, max_iters, gamma)\n",
    "    #predict \n",
    "    # choisi la methode de test qui t'interresse (commente l'autre)\n",
    "    yp = predict_labels_mse(w,cleaned_x_test_1)\n",
    "    #yp = predict_labels_logistic(w, cleaned_x_test_1)\n",
    "\n",
    "    # mesure accuracy\n",
    "    acc = measure_accuracy(y_test_1, yp)\n",
    "    f1 = measure_f1_score(y_test_1, yp)\n",
    "    accs.append(acc)\n",
    "    f1s.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8209874034945144, 0.3541446566436408, 0.9107984559122309, 0.9108594067452255, 0.909548963835839, 0.9098841934173101, 0.9081064607882975, 0.9089902478667209, 0.9093559528646892, 0.8793071921982933]\n",
      "[0.0957512315270936, 0.19319306616583334, 0.0004553215708594195, 0.0, 0.014390081912773965, 0.012467995101859067, 0.013737461840383776, 0.013434643761700253, 0.009546009546009546, 0.1363669404666715]\n"
     ]
    }
   ],
   "source": [
    "print(accs)\n",
    "print(f1s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.63 / 0.219 : entre 0.0156 et 0.0159 \n",
    "0.837 : 0.153 : 0.0156\n",
    "0.88 / 0.148 : 0.0157\n",
    "\n",
    "Visiblement rester a des chiffres exacts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[0.9109101991060544, 0.8207029662738724, 0.9089800893945551, 0.9085331166192605, 0.9055160503860219, 0.6329642421779764, 0.9071820398212109, 0.9067249085737505, 0.13592035757822024, 0.13160300690776108, 0.9076696464851687, 0.9055160503860219, 0.7161722876879317, 0.7563490451036164, 0.9104937017472572, 0.9076594880130029, 0.09873019097927671, 0.22479683055668429, 0.6392929703372613, 0.9107273466070703, 0.8376980902072328, 0.09902478667208452, 0.31964648516863065, 0.0904611946363267]\n",
    "[0.00022799817601459188, 0.09291807996710864, 0.03135135135135135, 0.006838738142510479, 0.02413178050571818, 0.21964968359214704, 0.025594539831502613, 0.047312720481427685, 0.15646879152700371, 0.16390364132507848, 0.052735799895779055, 0.054103528933184174, 0.1750324790362584, 0.19310344827586207, 0.0036186814429492254, 0.018570503131073203, 0.163112071161084, 0.1593575465150864, 0.12429712932820361, 0.00022753128555176336, 0.0610049955921246, 0.16367751060820368, 0.1621756861567715, 0.1635135513887721]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.910930516050386, 0.910930516050386, 0.9099756196668021, 0.8630434782608696, 0.6709670865501829, 0.2854937017472572, 0.5486286062576189, 0.9109203575782202, 0.9109203575782202, 0.910930516050386, 0.9095184884193417, 0.9108187728565623, 0.910930516050386, 0.910930516050386, 0.09434173100365705, 0.910930516050386, 0.08906948394961398, 0.08906948394961398, 0.08907964242177976, 0.08906948394961398]\n",
      "[0.0, 0.0, 0.022501654533421574, 0.21970135432341706, 0.1793767418292374, 0.14222298104831826, 0.13871174087499272, 0.0, 0.0, 0.0, 0.0017931189061974671, 0.0, 0.0, 0.0, 0.1627018041454962, 0.0, 0.16356988284456384, 0.16356988284456384, 0.16357140858339475, 0.16356988284456384]\n"
     ]
    }
   ],
   "source": [
    "# Previous Test cant remember param gamma rip for the 0.86 : 0.22\n",
    "print(accs)\n",
    "print(f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tu peux plot tes tableaux ici ca fait ton parametre x accuracies et f1 \n",
    "# (change le gammas si t'as chang√© de param la haut)\n",
    "plt.plot(gammas,accs,\"r\")\n",
    "plt.plot(gammas, f1s, \"b\")\n",
    "\n",
    "plt.title(\"accuracy/f1\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.xlabel(\"gammas\")\n",
    "plt.ylabel(\"Accuracy and F1 (%)\")\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9035757822023568"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing which method is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy ridge:\n",
      "0.9063693620479479\n",
      "f1 ridge:\n",
      "0.19382489285401908\n",
      "accuracy mse gd:\n",
      "0.910930516050386\n",
      "f1 mse gd:\n",
      "0.0\n",
      "accuracy mse sgd:\n",
      "0.8993295408370581\n",
      "f1 mse sgd:\n",
      "0.15385928961748635\n",
      "accuracy least squares:\n",
      "0.910930516050386\n",
      "f1 mse least squares:\n",
      "0.0\n",
      "accuracy logistic reg:\n",
      "0.910930516050386\n",
      "f1 mse logistic reg:\n",
      "0.0\n",
      "accuracy reg logistic reg:\n",
      "0.910930516050386\n",
      "f1 mse reg logistic reg:\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "gamma = 0.01\n",
    "lambda_ = 0.0000001\n",
    "max_iters = 1000\n",
    "degree = 9\n",
    "initial_w = np.zeros(cleaned_x_train_1.shape[1])\n",
    "\n",
    "# ridge\n",
    "poly_train = build_poly(cleaned_x_train_1, degree)\n",
    "w, loss = ridge_regression(y_train_1, poly_train, lambda_)\n",
    "poly_test = build_poly(cleaned_x_test_1, degree)\n",
    "yp = predict_labels_mse(w, poly_test)\n",
    "\n",
    "print(\"accuracy ridge:\")\n",
    "accuracy = measure_accuracy(y_test_1, yp)\n",
    "print(accuracy)\n",
    "print(\"f1 ridge:\")\n",
    "f1 = measure_f1_score(y_test_1, yp)\n",
    "print(f1)\n",
    "\n",
    "# mse gd\n",
    "w, loss = mean_squared_error_gd(y_train_1, cleaned_x_train_1, initial_w, max_iters, gamma)\n",
    "yp = predict_labels_mse(w, cleaned_x_test_1)\n",
    "\n",
    "print(\"accuracy mse gd:\")\n",
    "accuracy = measure_accuracy(y_test_1, yp)\n",
    "print(accuracy)\n",
    "print(\"f1 mse gd:\")\n",
    "f1 = measure_f1_score(y_test_1, yp)\n",
    "print(f1)\n",
    "\n",
    "# mse sgd\n",
    "w, loss = mean_squared_error_sgd(y_train_1, cleaned_x_train_1, initial_w, max_iters, gamma)\n",
    "yp = predict_labels_mse(w, cleaned_x_test_1)\n",
    "\n",
    "print(\"accuracy mse sgd:\")\n",
    "accuracy = measure_accuracy(y_test_1, yp)\n",
    "print(accuracy)\n",
    "print(\"f1 mse sgd:\")\n",
    "f1 = measure_f1_score(y_test_1, yp)\n",
    "print(f1)\n",
    "\n",
    "# mse sgd\n",
    "w, loss = least_squares(y_train_1, cleaned_x_train_1)\n",
    "yp = predict_labels_mse(w, cleaned_x_test_1)\n",
    "\n",
    "print(\"accuracy least squares:\")\n",
    "accuracy = measure_accuracy(y_test_1, yp)\n",
    "print(accuracy)\n",
    "print(\"f1 mse least squares:\")\n",
    "f1 = measure_f1_score(y_test_1, yp)\n",
    "print(f1)\n",
    "\n",
    "# logistic reg\n",
    "w, loss = logistic_regression(y_train_1, cleaned_x_train_1, initial_w, max_iters, gamma)\n",
    "yp = predict_labels_logistic(w, cleaned_x_test_1)\n",
    "\n",
    "print(\"accuracy logistic reg:\")\n",
    "accuracy = measure_accuracy(y_test_1, yp)\n",
    "print(accuracy)\n",
    "print(\"f1 mse logistic reg:\")\n",
    "f1 = measure_f1_score(y_test_1, yp)\n",
    "print(f1)\n",
    "\n",
    "#  reg logistic reg\n",
    "w, loss = reg_logistic_regression(y_train_1, cleaned_x_train_1, lambda_, initial_w, max_iters, gamma)\n",
    "yp = predict_labels_logistic(w, cleaned_x_test_1)\n",
    "\n",
    "print(\"accuracy reg logistic reg:\")\n",
    "accuracy = measure_accuracy(y_test_1, yp)\n",
    "print(accuracy)\n",
    "print(\"f1 mse reg logistic reg:\")\n",
    "f1 = measure_f1_score(y_test_1, yp)\n",
    "print(f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamdas = 0.0000001\n",
    "accs = []\n",
    "f1s = []\n",
    "degrees = range(25)\n",
    "for deg in degrees:\n",
    "\n",
    "    # ridge\n",
    "    poly_train = build_poly(cleaned_x_train_1, deg)\n",
    "    w, loss = ridge_regression(y_train_1, poly_train, lamdas)\n",
    "    poly_test = build_poly(cleaned_x_test_1, deg)\n",
    "    yp = predict_labels_mse(w, poly_test)\n",
    "\n",
    "    accuracy = measure_accuracy(y_test_1, yp)\n",
    "    f1 = measure_f1_score(y_test_1, yp)\n",
    "    accs.append(accuracy)\n",
    "    f1s.append(f1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
