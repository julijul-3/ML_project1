{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import *\n",
    "from implementations import *\n",
    "\n",
    "# from test_utils import test\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run de A a Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading  data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, train_ids, test_ids = load_csv_data(\"dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.genfromtxt(\"dataset/x_test.csv\", delimiter=\",\", dtype = str, max_rows=1)\n",
    "labels = np.delete(labels,0) # delete the label 'id' as we dont have it in x_train and x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the high number of features with all different exceptions values and linearity, we decided to select manually the features we found relevant. The list below is the name of the feature, the exception values that we have to remplace, and wheter we remplace by majority (True) or by the mean (False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = [(\"MSCODE\", [], True),\n",
    "            (\"_HCVU651\", [9], True),\n",
    "            (\"_RFHYPE5\", [9], True),\n",
    "            (\"_RFCHOL\", [9], True),\n",
    "            (\"_RACE\",[9], True),\n",
    "            (\"_BMI5\",[], False),\n",
    "            (\"_EDUCAG\",[9], True),\n",
    "            (\"_INCOMG\",[9], True),\n",
    "            (\"_SMOKER3\",[9], True),\n",
    "            (\"_DRNKWEK\",[99900], True),\n",
    "            (\"_FRUTSUM\",[], True),\n",
    "            (\"_VEGESUM\",[], True),\n",
    "            (\"PA1MIN_\",[], True),\n",
    "            (\"GENHLTH\",[7,9], False),\n",
    "            (\"CHECKUP1\",[7,9], False),\n",
    "            (\"MENTHLTH\",[88, 77, 99], False),\n",
    "            (\"BPHIGH4\",[7,9], True),\n",
    "            (\"BPMEDS\",[7,9], True),\n",
    "            (\"TOLDHI2\",[7,9], True),\n",
    "            (\"CHCOCNCR\",[7,8,9], True),\n",
    "            (\"DIABETE3\",[7,8,9], True),\n",
    "            (\"SEX\",[], True),\n",
    "            (\"QLACTLM2\",[7,9], True),\n",
    "            (\"AVEDRNK2\",[77, 99], False),\n",
    "            (\"EXERANY2\",[7,9], True),\n",
    "            (\"SHINGLE2\", [7,9], True),\n",
    "            (\"LMTJOIN3\", [7,9], True),\n",
    "            (\"CVDASPRN\", [7,9], True)\n",
    "            ]\n",
    "cleaned_x_train = clean_data(labels, label_list, x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 2., 2., 2.],\n",
       "       [5., 1., 2., ..., 2., 2., 2.],\n",
       "       [1., 1., 1., ..., 2., 2., 2.],\n",
       "       ...,\n",
       "       [1., 1., 1., ..., 2., 2., 2.],\n",
       "       [5., 1., 1., ..., 2., 2., 2.],\n",
       "       [1., 1., 2., ..., 2., 2., 2.]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = np.corrcoef(cleaned_x_train, rowvar=False)\n",
    "\n",
    "# Define a correlation threshold (for example, 0.7)\n",
    "correlation_threshold = 0.7\n",
    "\n",
    "# Find the indices of uncorrelated columns\n",
    "uncorrelated_indices = np.where(np.abs(correlation_matrix) < correlation_threshold)\n",
    "\n",
    "# Get the unique column indices of uncorrelated variables\n",
    "uncorrelated_columns = np.unique(uncorrelated_indices[1])\n",
    "\n",
    "# Create a new dataset with uncorrelated variables\n",
    "uncorrelated_data = cleaned_x_train[:, uncorrelated_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ca change rien mdr ya tjr 28 dans le resultat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning in another way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.7  # You want to drop columns with > 50% NaNs\n",
    "column_count = x_train.shape[0]\n",
    "max_nan_count = threshold * column_count\n",
    "\n",
    "# Create a mask to identify columns with too many NaNs\n",
    "nan_mask = np.sum(np.isnan(x_train), axis=0) <= max_nan_count\n",
    "\n",
    "# Use the mask to select the columns with fewer NaNs\n",
    "x_train_filtered = x_train[:, nan_mask]\n",
    "x_test_filtered = x_test[:, nan_mask]\n",
    "\n",
    "# drop the "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split for our own cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_1, y_train_1, x_test_1, y_test_1 = split_train_test(y_train, x_train, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_x_train_1 = clean_data(labels, label_list, x_train_1)\n",
    "cleaned_x_test_1 = clean_data(labels, label_list, x_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.728971962616825\n",
      "46.728971962616825\n",
      "42.05607476635514\n",
      "32.398753894081\n",
      "38.940809968847354\n",
      "41.43302180685358\n",
      "44.54828660436137\n",
      "41.74454828660436\n",
      "41.74454828660436\n",
      "44.85981308411215\n",
      "50.155763239875384\n",
      "42.99065420560748\n",
      "46.10591900311526\n",
      "42.679127725856695\n",
      "36.7601246105919\n",
      "38.006230529595015\n",
      "43.925233644859816\n",
      "42.05607476635514\n",
      "50.77881619937694\n",
      "38.31775700934579\n",
      "39.56386292834891\n",
      "45.17133956386293\n",
      "30.8411214953271\n",
      "42.679127725856695\n",
      "42.36760124610592\n",
      "47.35202492211838\n",
      "52.024922118380054\n",
      "47.66355140186916\n"
     ]
    }
   ],
   "source": [
    "# want to see which labels are way to small\n",
    "\n",
    "for label in label_list:\n",
    "    l, _, _ = label\n",
    "    id = np.where(labels == l)[0][0]\n",
    "    x = x_train[:][id]\n",
    "\n",
    "    # Count the number of NaN values\n",
    "    nans= np.count_nonzero(np.isnan(x))\n",
    "    nan_perc = nans/len(x) *100\n",
    "    print(nan_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/Julie/Desktop/EPFL/MA3/ML/ML_project1/run.ipynb Cellule 19\u001b[0m line \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Julie/Desktop/EPFL/MA3/ML/ML_project1/run.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m degree \u001b[39m=\u001b[39m \u001b[39m25\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Julie/Desktop/EPFL/MA3/ML/ML_project1/run.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m## tx is cleaned data \u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/Julie/Desktop/EPFL/MA3/ML/ML_project1/run.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m poly \u001b[39m=\u001b[39m build_poly(cleaned_x_train,degree)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Julie/Desktop/EPFL/MA3/ML/ML_project1/run.ipynb#X22sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m w , loss \u001b[39m=\u001b[39m ridge_regression(y_train,poly,lambda_)\n",
      "File \u001b[0;32m~/Desktop/EPFL/MA3/ML/ML_project1/helpers.py:171\u001b[0m, in \u001b[0;36mbuild_poly\u001b[0;34m(x, degree)\u001b[0m\n\u001b[1;32m    169\u001b[0m poly \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mones((\u001b[39mlen\u001b[39m(x), \u001b[39m1\u001b[39m))\n\u001b[1;32m    170\u001b[0m \u001b[39mfor\u001b[39;00m deg \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, degree\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m--> 171\u001b[0m     poly \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mc_[poly, np\u001b[39m.\u001b[39;49mpower(x, deg)]\n\u001b[1;32m    172\u001b[0m \u001b[39mreturn\u001b[39;00m poly\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/project1-grading/lib/python3.9/site-packages/numpy/lib/index_tricks.py:412\u001b[0m, in \u001b[0;36mAxisConcatenator.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m scalars:\n\u001b[1;32m    410\u001b[0m         objs[k] \u001b[39m=\u001b[39m objs[k]\u001b[39m.\u001b[39mastype(final_dtype)\n\u001b[0;32m--> 412\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconcatenate(\u001b[39mtuple\u001b[39;49m(objs), axis\u001b[39m=\u001b[39;49maxis)\n\u001b[1;32m    414\u001b[0m \u001b[39mif\u001b[39;00m matrix:\n\u001b[1;32m    415\u001b[0m     oldndim \u001b[39m=\u001b[39m res\u001b[39m.\u001b[39mndim\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lambda_ = 0.0001\n",
    "degree = 25\n",
    "## tx is cleaned data \n",
    "poly = build_poly(cleaned_x_train,degree)\n",
    "w , loss = ridge_regression(y_train,poly,lambda_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean squared errors gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.869667297614137\n",
      "[-1.72085509e+00 -9.30040015e-01 -1.28523323e+00 -1.23906547e+00\n",
      " -1.36976592e+00  1.55401702e-01 -2.62913319e+00 -3.53316604e+00\n",
      " -2.67733242e+00 -1.53469647e+03 -1.24644760e+00 -1.87751007e+00\n",
      " -1.57560746e+03  8.08858339e-02 -3.84832516e-02 -3.50061236e-02\n",
      " -1.82381716e+00 -9.45322311e-01 -1.39279456e+00 -1.65070826e+00\n",
      " -2.44492919e+00 -1.20890430e+00 -1.54224877e+00 -1.08368453e+00\n",
      " -9.47441330e-01 -1.73183383e+00 -1.61392145e+00 -1.73956716e+00]\n",
      "125.92674705873003\n",
      "[ 1.65447846e+01  9.51163494e+00  1.23609611e+01  1.19896931e+01\n",
      "  1.55815586e+01 -9.20034449e-01  2.66993049e+01  3.60728794e+01\n",
      "  2.84670134e+01  1.03250000e+04  1.16148440e+01  1.76681097e+01\n",
      "  8.50647501e+03 -1.21642922e+00  5.34033491e-01 -7.35401238e-03\n",
      "  1.97719777e+01  9.54801930e+00  1.46760470e+01  1.69188093e+01\n",
      "  2.50637134e+01  1.31517562e+01  1.58978233e+01  6.78835552e+00\n",
      "  1.03370425e+01  1.76005015e+01  1.65955797e+01  1.76654972e+01]\n",
      "4747.788793366803\n",
      "[-9.07519082e+01 -5.23404803e+01 -6.83101054e+01 -6.61704306e+01\n",
      " -8.46600658e+01  5.48752812e+00 -1.47066058e+02 -1.98788658e+02\n",
      " -1.54734155e+02 -6.72146686e+04 -6.37800525e+01 -9.75562205e+01\n",
      " -4.81179349e+04  6.54720799e+00 -3.40134384e+00 -3.10766710e-01\n",
      " -1.08131096e+02 -5.26118106e+01 -8.04931303e+01 -9.30169323e+01\n",
      " -1.38007365e+02 -7.11921683e+01 -8.73170174e+01 -4.63281964e+01\n",
      " -5.67428415e+01 -9.67907643e+01 -9.12369383e+01 -9.71473607e+01]\n",
      "182780.6773262307\n",
      "[ 5.53661835e+02  3.21183579e+02  4.18218615e+02  4.05043991e+02\n",
      "  5.20020815e+02 -3.33554884e+01  9.02442052e+02  1.22052820e+03\n",
      "  9.46551746e+02  4.29759621e+05  3.88418489e+02  5.96095016e+02\n",
      "  2.81650618e+05 -4.06493883e+01  2.25074977e+01  2.07169059e+00\n",
      "  6.64188932e+02  3.22777221e+02  4.94169361e+02  5.70637919e+02\n",
      "  8.47255072e+02  4.35312157e+02  5.35630418e+02  2.99995008e+02\n",
      "  3.49276771e+02  5.93522541e+02  5.59832350e+02  5.95675649e+02]\n",
      "7083951.040566154\n",
      "[-3.37288467e+03 -1.96272219e+03 -2.55416934e+03 -2.47312294e+03\n",
      " -3.17467836e+03  2.04718763e+02 -5.51530204e+03 -7.46168717e+03\n",
      " -5.76768704e+03 -2.71986581e+06 -2.36452753e+03 -3.63677425e+03\n",
      " -1.68763597e+06  2.49137280e+02 -1.44188359e+02 -1.46202994e+01\n",
      " -4.05782016e+03 -1.97255758e+03 -3.01935097e+03 -3.48631883e+03\n",
      " -5.17896095e+03 -2.65070296e+03 -3.27195790e+03 -1.91627377e+03\n",
      " -2.13689715e+03 -3.62547739e+03 -3.42061722e+03 -3.63852964e+03]\n",
      "275210049.1424658\n",
      "[ 2.07707055e+04  1.21110005e+04  1.57525991e+04  1.52508228e+04\n",
      "  1.95825731e+04 -1.26449918e+03  3.40337523e+04  4.60538542e+04\n",
      "  3.55317271e+04  1.71115503e+07  1.45536545e+04  2.24144878e+04\n",
      "  1.02677878e+07 -1.54115998e+03  9.14587687e+02  9.63427365e+01\n",
      "  2.50385621e+04  1.21716904e+04  1.86304902e+04  2.15095557e+04\n",
      "  3.19624099e+04  1.63237724e+04  2.01855075e+04  1.21171224e+04\n",
      "  1.31968631e+04  2.23652683e+04  2.11055156e+04  2.24453787e+04]\n",
      "10701118116.999224\n",
      "[-1.28519591e+05 -7.50283275e+04 -9.75603468e+04 -9.44450939e+04\n",
      " -1.21284273e+05  7.84058533e+03 -2.10847377e+05 -2.85350040e+05\n",
      " -2.19896745e+05 -1.07278504e+08 -9.00240542e+04 -1.38763387e+05\n",
      " -6.30760659e+07  9.56109308e+03 -5.76048150e+03 -6.21377955e+02\n",
      " -1.55110839e+05 -7.54046756e+04 -1.15413881e+05 -1.33242037e+05\n",
      " -1.98030013e+05 -1.01000434e+05 -1.25034125e+05 -7.61974979e+04\n",
      " -8.17957689e+04 -1.38532348e+05 -1.30744064e+05 -1.39027042e+05]\n",
      "416226194064.10535\n",
      "[ 7.97778020e+05  4.66078071e+05  6.05940511e+05  5.86563546e+05\n",
      "  7.53310184e+05 -4.87299678e+04  1.30981316e+06  1.77276680e+06\n",
      "  1.36516589e+06  6.71174642e+08  5.58715431e+05  8.61638356e+05\n",
      "  3.89804279e+08 -5.94457354e+04  3.61397327e+04  3.95100174e+03\n",
      "  9.63539542e+05  4.68416983e+05  7.16944122e+05  8.27662572e+05\n",
      "  1.23024735e+06  6.26945897e+05  7.76654942e+05  4.77575274e+05\n",
      "  5.08271486e+05  8.60484844e+05  8.12164322e+05  8.63551873e+05]\n",
      "16191174316891.223\n",
      "[-4.96155806e+06 -2.89993444e+06 -3.76975752e+06 -3.64910021e+06\n",
      " -4.68666830e+06  3.03289855e+05 -8.14973647e+06 -1.10307603e+07\n",
      " -8.49089706e+06 -4.19393767e+09 -3.47438600e+06 -5.35974578e+06\n",
      " -2.41776952e+09  3.70064985e+05 -2.26196436e+05 -2.49261110e+04\n",
      " -5.99508267e+06 -2.91449136e+06 -4.46078181e+06 -5.14955763e+06\n",
      " -7.65488831e+06 -3.89907830e+06 -4.83211365e+06 -2.98739415e+06\n",
      " -3.16303784e+06 -5.35362287e+06 -5.05319971e+06 -5.37268330e+06]\n",
      "629861112644854.9\n",
      "[ 3.08925820e+07  1.80609606e+07  2.34767677e+07  2.27249549e+07\n",
      "  2.91872650e+07 -1.88925095e+06  5.07573638e+07  6.87025330e+07\n",
      "  5.28699781e+07  2.61871386e+10  2.16314132e+07  3.33756996e+07\n",
      "  1.50295387e+10 -2.30551475e+06  1.41376969e+06  1.56525762e+05\n",
      "  3.73375269e+07  1.81516374e+07  2.77818625e+07  3.20711714e+07\n",
      "  4.76762075e+07  2.42770378e+07  3.00938315e+07  1.86653363e+07\n",
      "  1.97017457e+07  3.33415214e+07  3.14713191e+07  3.34601461e+07]\n"
     ]
    }
   ],
   "source": [
    "gamma = 0.00001\n",
    "max_iters = 10\n",
    "w_initial = np.zeros(cleaned_x_train.shape[1])\n",
    "\n",
    "w, loss = mean_squared_error_gd(y_train, cleaned_x_train, w_initial, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "635309514315469.8"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean squared error sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.00001\n",
    "max_iters = 100\n",
    "w_initial = np.zeros(cleaned_x_train.shape[1])\n",
    "\n",
    "w, loss = mean_squared_error_sgd(y_train, cleaned_x_train, w_initial, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Least squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, loss = least_squares(y_train, cleaned_x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iters = 1000\n",
    "gamma = 0.01\n",
    "w_initial = np.zeros(cleaned_x_train.shape[1])\n",
    "w, loss = logistic_regression(y_train, cleaned_x_train, w_initial, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reg logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iters = 1000\n",
    "gamma = 0.01\n",
    "lambda_ = 0.001\n",
    "w_initial = np.zeros(cleaned_x_train.shape[1])\n",
    "w, loss = reg_logistic_regression(y_train, cleaned_x_train, lambda_, w_initial, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.49381024e+01 -8.85547909e+00 -1.09454655e+01 -1.06978012e+01\n",
      " -1.58527911e+01  2.98766478e-01 -2.46889621e+01 -3.34267239e+01\n",
      " -2.79333666e+01 -2.13884415e+03 -1.02365183e+01 -1.54473970e+01\n",
      " -3.09382822e+03  1.41175871e+00 -3.76759553e-01  3.61997464e-01\n",
      " -1.93217681e+01 -8.79168349e+00 -1.40192604e+01 -1.58082116e+01\n",
      " -2.33299024e+01 -1.31922831e+01 -1.49417766e+01 -6.09203394e-02\n",
      " -1.00471419e+01 -1.63503805e+01 -1.55373523e+01 -1.64034335e+01]\n",
      "nan\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "print(w)\n",
    "print(loss)\n",
    "print(len(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up x test\n",
    "\n",
    "cleaned_x_test = clean_data(labels, label_list, x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109379, 29)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_test = build_poly(cleaned_x_test,degree)\n",
    "poly_test.shape\n",
    "                                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# notes for next one working on this lol\n",
    "\n",
    "ridge -> build poly -> predict label: Ca marche mais pas très bons résultats (mieux si tu montes le degré mais tres bas F1)\n",
    "\n",
    "least squares -> predict label : marche pas avec build poly pck pas les bonnes dims (build poly rajoute une colonne, donc impossible de faire data@weight) Ca marche sans, mais on a que 1 valeur a 1, le reste a -1 (et ya pas de params a changer) F1 SCORE 0.000 ACCURACY 0.912\n",
    "\n",
    "mean squared gd -> (same thing pour build poly) les valeurs sont fucked up mdr [1.13497280e+79 1.72690226e+79 3.20689183e+78 ... 1.36781180e+78 1.99141883e+78 1.76606508e+78] c'est du 10^78 a peu pres, donc ya tout qui fini par etre a 1 et rien a -1 \n",
    "\n",
    "mean squared sgd -> same as gd mais on est plutot dans du 10^14, et que des negatifs\n",
    "\n",
    "J'ai aussi tenté ridge en filtrant les données d'une autre manière, aka juste prendre les colonnes qui ont plus que 70% de données (par rapport aux nan) et ca me donne des meilleurs résultats... snif snif donc F1 SCORE 0.139 ACCURACY 0.837 Après j'ai rien clean up or anything donc c'est un peu ridicule genre ya toutes les valeurs d'exceptions encore (en vrai j'ai aucune idée de pourquoi ca a marché ??? Pck j'ai pas enlevé les nan ?? Donc ca a du bader hahahaha)\n",
    "\n",
    "Si je mets 1000 max_iters ca overflow error, donc j'ai laissé 100, a tester avec 500 par exemple\n",
    "\n",
    "Idées: Peut être que normalizer les data ca change qqch mour les deux mean squares ? \n",
    "\n",
    "Questions TA:\n",
    "- regarder nos logisitc methods\n",
    "- pk ca marche pas lol\n",
    "- est - ce que c'est une bonne idée la manière dont on fait ou est-ce qu'il nous faut beaucoup plus de colonnes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### noms des variables et valeurs utilisées\n",
    "\n",
    "- cleaned_x_train/test : data nettoyée avec nos 28 colonnes choisies\n",
    "- x_train/test_filtered : data avec enlevé ceux avec moins de 70% de donnees\n",
    "- x_train_1 etc: c'est x_train cleaned de la meme manière mais ils sont divisé en test/train pour nous meme faire cross validation\n",
    "\n",
    "- degres: pour ridge utiliser un grand chiffre, pour le reste utiliser 1 (bah en fait c'est juste pour build poly donc pas utiliser (je crois, j'ai pas trouvé de valuers qui marche))\n",
    "\n",
    "- max_iters: j'ai l'impression que plus je mets grand, plus mes y_pred sont grands (why??????) (avec 1, j'ai que des -1.3 environ, quand je mets 2 j'ai entre 1 et 20, quand je mets 100 j'ai 10^78 lol) Ca explique le overflow error quand je mets 1000 i guess\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities: [1. 1. 1. ... 1. 1. 1.]\n",
      "Predictions: [1 1 1 ... 1 1 1]\n",
      "[31235666.01094589 47133714.72771978  8778353.65629169 ...\n",
      "  3749995.10943686  5449352.59114688  4832982.84000415]\n"
     ]
    }
   ],
   "source": [
    "# predict for logistic\n",
    "\n",
    "z = np.dot(cleaned_x_test, w)\n",
    "probabilities = sigmoid(z)\n",
    "\n",
    "# Make binary predictions using a threshold (e.g., 0.5)\n",
    "predictions = (probabilities >= 0.5).astype(int)\n",
    "\n",
    "print(\"Probabilities:\", probabilities)\n",
    "print(\"Predictions:\", predictions)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4641585.46116621 -3124351.82067069 -1004162.20713698 ...\n",
      "  -557609.27908091  -658199.64302265  -718567.26561789]\n"
     ]
    }
   ],
   "source": [
    "yp = predict_labels(w,cleaned_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(np.where(yp == 1)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSV Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_submission(test_ids,yp,\"outputs/ridge_degre25_200features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## let me do loops and stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (98440,197) and (28,) not aligned: 197 (dim 1) != 28 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/Julie/Desktop/EPFL/MA3/ML/ML_project1/run.ipynb Cellule 38\u001b[0m line \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Julie/Desktop/EPFL/MA3/ML/ML_project1/run.ipynb#X50sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m poly_test \u001b[39m=\u001b[39m build_poly(cleaned_x_test_1,\u001b[39m7\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Julie/Desktop/EPFL/MA3/ML/ML_project1/run.ipynb#X50sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m#predict\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Julie/Desktop/EPFL/MA3/ML/ML_project1/run.ipynb#X50sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m yp \u001b[39m=\u001b[39m predict_labels(w,poly_test)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Julie/Desktop/EPFL/MA3/ML/ML_project1/run.ipynb#X50sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# mesure accuracy\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Julie/Desktop/EPFL/MA3/ML/ML_project1/run.ipynb#X50sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m acc \u001b[39m=\u001b[39m measure_accuracy(y_test_1, yp)\n",
      "File \u001b[0;32m~/Desktop/EPFL/MA3/ML/ML_project1/helpers.py:408\u001b[0m, in \u001b[0;36mpredict_labels\u001b[0;34m(weights, data)\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict_labels\u001b[39m(weights, data):\n\u001b[1;32m    407\u001b[0m     \u001b[39m\"\"\"Generates class predictions given weights, and a test data matrix\"\"\"\u001b[39;00m\n\u001b[0;32m--> 408\u001b[0m     y_pred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mdot(data, weights)\n\u001b[1;32m    409\u001b[0m     \u001b[39mprint\u001b[39m((y_pred))\n\u001b[1;32m    410\u001b[0m     y_pred[np\u001b[39m.\u001b[39mwhere(y_pred \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m)] \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (98440,197) and (28,) not aligned: 197 (dim 1) != 28 (dim 0)"
     ]
    }
   ],
   "source": [
    "N = 10\n",
    "gammas = np.linspace(0.0001, 0.1, N)\n",
    "max_iters_arr = np.linspace(1, 200, N)\n",
    "initial_w = np.zeros(cleaned_x_train_1.shape[1])\n",
    "accs = []\n",
    "f1s = []\n",
    "\n",
    "for gamma in gammas:\n",
    "    # train\n",
    "    w, loss = ridge_regression(y_train_1, cleaned_x_train_1, gamma)\n",
    "    poly_test = build_poly(cleaned_x_test_1,7)\n",
    "\n",
    "    #predict\n",
    "    # si pas ridge met cleaned_x_test_1 a la place de poly_test\n",
    "    yp = predict_labels(w,poly_test)\n",
    "\n",
    "    # mesure accuracy\n",
    "    acc = measure_accuracy(y_test_1, yp)\n",
    "    f1 = measure_f1_score(y_test_1, yp)\n",
    "    accs.append(acc)\n",
    "    f1s.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08906948394961398, 0.08906948394961398, 0.08906948394961398, 0.08906948394961398, 0.08906948394961398, 0.08906948394961398, 0.08906948394961398, 0.08906948394961398, 0.08906948394961398, 0.08906948394961398]\n",
      "[0.16356988284456384, 0.16356988284456384, 0.16356988284456384, 0.16356988284456384, 0.16356988284456384, 0.16356988284456384, 0.16356988284456384, 0.16356988284456384, 0.16356988284456384, 0.16356988284456384]\n"
     ]
    }
   ],
   "source": [
    "print(accs)\n",
    "print(f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(gammas,accs,\"r\")\n",
    "plt.plot(gammas, f1s, \"b\")\n",
    "\n",
    "plt.title(\"Mean squared error gd accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.xlabel(\"Gamma\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
