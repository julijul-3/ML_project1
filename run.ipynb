{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import *\n",
    "from implementations import *\n",
    "\n",
    "# from test_utils import test\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run de A a Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading  data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, train_ids, test_ids = load_csv_data(\"dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.genfromtxt(\"dataset/x_test.csv\", delimiter=\",\", dtype = str, max_rows=1)\n",
    "labels = np.delete(labels,0) # delete the label 'id' as we dont have it in x_train and x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the high number of features with all different exceptions values and linearity, we decided to select manually the features we found relevant. The list below is the name of the feature, the exception values that we have to remplace, and wheter we remplace by majority (True) or by the mean (False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = [(\"MSCODE\", [], True),\n",
    "            (\"_HCVU651\", [9], True),\n",
    "            (\"_RFHYPE5\", [9], True),\n",
    "            (\"_RFCHOL\", [9], True),\n",
    "            (\"_RACE\",[9], True),\n",
    "            (\"_BMI5\",[], False),\n",
    "            (\"_EDUCAG\",[9], True),\n",
    "            (\"_INCOMG\",[9], True),\n",
    "            (\"_SMOKER3\",[9], True),\n",
    "            (\"_DRNKWEK\",[99900], True),\n",
    "            (\"_FRUTSUM\",[], True),\n",
    "            (\"_VEGESUM\",[], True),\n",
    "            (\"PA1MIN_\",[], True),\n",
    "            (\"GENHLTH\",[7,9], False),\n",
    "            (\"CHECKUP1\",[7,9], False),\n",
    "            (\"MENTHLTH\",[88, 77, 99], False),\n",
    "            (\"BPHIGH4\",[7,9], True),\n",
    "            (\"BPMEDS\",[7,9], True),\n",
    "            (\"TOLDHI2\",[7,9], True),\n",
    "            (\"CHCOCNCR\",[7,8,9], True),\n",
    "            (\"DIABETE3\",[7,8,9], True),\n",
    "            (\"SEX\",[], True),\n",
    "            (\"QLACTLM2\",[7,9], True),\n",
    "            (\"AVEDRNK2\",[77, 99], False),\n",
    "            (\"EXERANY2\",[7,9], True),\n",
    "            (\"SHINGLE2\", [7,9], True),\n",
    "            (\"LMTJOIN3\", [7,9], True),\n",
    "            (\"CVDASPRN\", [7,9], True)\n",
    "            ]\n",
    "cleaned_x_train = clean_data(labels, label_list, x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning in another way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.7  # You want to drop columns with > 50% NaNs\n",
    "column_count = x_train.shape[0]\n",
    "max_nan_count = threshold * column_count\n",
    "\n",
    "# Create a mask to identify columns with too many NaNs\n",
    "nan_mask = np.sum(np.isnan(x_train), axis=0) <= max_nan_count\n",
    "\n",
    "# Use the mask to select the columns with fewer NaNs\n",
    "x_train_filtered = x_train[:, nan_mask]\n",
    "x_test_filtered = x_test[:, nan_mask]\n",
    "\n",
    "# drop the "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split for our own cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_1, y_train_1, x_test_1, y_test_1 = split_train_test(y_train, x_train, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_x_train_1 = clean_data(labels, label_list, x_train_1)\n",
    "cleaned_x_test_1 = clean_data(labels, label_list, x_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.728971962616825\n",
      "46.728971962616825\n",
      "42.05607476635514\n",
      "32.398753894081\n",
      "38.940809968847354\n",
      "41.43302180685358\n",
      "44.54828660436137\n",
      "41.74454828660436\n",
      "41.74454828660436\n",
      "44.85981308411215\n",
      "50.155763239875384\n",
      "42.99065420560748\n",
      "46.10591900311526\n",
      "42.679127725856695\n",
      "36.7601246105919\n",
      "38.006230529595015\n",
      "43.925233644859816\n",
      "42.05607476635514\n",
      "50.77881619937694\n",
      "38.31775700934579\n",
      "39.56386292834891\n",
      "45.17133956386293\n",
      "30.8411214953271\n",
      "42.679127725856695\n",
      "42.36760124610592\n",
      "47.35202492211838\n",
      "52.024922118380054\n",
      "47.66355140186916\n"
     ]
    }
   ],
   "source": [
    "# want to see which labels are way to small\n",
    "\n",
    "for label in label_list:\n",
    "    l, _, _ = label\n",
    "    id = np.where(labels == l)[0][0]\n",
    "    x = x_train[:][id]\n",
    "\n",
    "    # Count the number of NaN values\n",
    "    nans= np.count_nonzero(np.isnan(x))\n",
    "    nan_perc = nans/len(x) *100\n",
    "    print(nan_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_ = 0.0001\n",
    "degree = 25\n",
    "## tx is cleaned data \n",
    "poly = build_poly(cleaned_x_train,degree)\n",
    "w , loss = ridge_regression(y_train,poly,lambda_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean squared errors gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.876059989445784\n",
      "[-1.73485780e+00 -9.38011905e-01 -1.29585163e+00 -1.24931575e+00\n",
      " -1.38391345e+00 -2.38188225e+01 -2.65089165e+00 -3.56246999e+00\n",
      " -2.70224664e+00 -1.53651777e+03 -1.25549341e+00 -1.89110299e+00\n",
      " -1.57837078e+03 -2.17627002e+00 -1.36434309e+00 -9.75091986e+00\n",
      " -1.83990496e+00 -9.53286893e-01 -1.40492730e+00 -1.66488961e+00\n",
      " -2.46525238e+00 -1.22063853e+00 -1.55524819e+00 -3.56398420e+00\n",
      " -9.56813038e-01 -1.74662282e+00 -1.62761910e+00 -1.75439078e+00]\n",
      "126.35408983675832\n",
      "[1.65739165e+01 9.52806732e+00 1.23825157e+01 1.20106047e+01\n",
      " 1.56083801e+01 2.43717246e+02 2.67454046e+01 3.61350423e+01\n",
      " 2.85166332e+01 1.03401475e+04 1.16353761e+01 1.76990290e+01\n",
      " 8.52338051e+03 2.14600634e+01 1.38861316e+01 9.60520855e+01\n",
      " 1.98059518e+01 9.56452935e+00 1.47013344e+01 1.69480586e+01\n",
      " 2.51069148e+01 1.31747076e+01 1.59252891e+01 2.95482088e+01\n",
      " 1.03547440e+01 1.76309798e+01 1.66242380e+01 1.76960926e+01]\n",
      "4767.401349091575\n",
      "[-9.10634418e+01 -5.25181104e+01 -6.85444120e+01 -6.63971182e+01\n",
      " -8.49613571e+01 -1.34011347e+03 -1.47558199e+02 -1.99452369e+02\n",
      " -1.55276357e+02 -6.73376345e+04 -6.39907549e+01 -9.78746432e+01\n",
      " -4.82374514e+04 -1.18399230e+02 -7.69864767e+01 -5.31207795e+02\n",
      " -1.08494218e+02 -5.27898189e+01 -8.07650476e+01 -9.33328836e+01\n",
      " -1.38468061e+02 -7.14448446e+01 -8.76103459e+01 -1.76547603e+02\n",
      " -5.69428318e+01 -9.71199766e+01 -9.15445296e+01 -9.74775888e+01]\n",
      "183656.36536585062\n",
      "[5.55591454e+02 3.22286864e+02 4.19669557e+02 4.06448314e+02\n",
      " 5.21869815e+02 8.21835551e+03 9.05510288e+02 1.22466849e+03\n",
      " 9.49892936e+02 4.30687703e+05 3.89737224e+02 5.98093884e+02\n",
      " 2.82466286e+05 7.25376965e+02 4.73786279e+02 3.25794028e+03\n",
      " 6.66451393e+02 3.23883697e+02 4.95860621e+02 5.72599961e+02\n",
      " 8.50129244e+02 4.36864321e+02 5.37457514e+02 1.10721235e+03\n",
      " 3.50506545e+02 5.95566194e+02 5.61746343e+02 5.97725941e+02]\n",
      "7122477.700305566\n",
      "[-3.38605646e+03 -1.97027377e+03 -2.56409078e+03 -2.48272466e+03\n",
      " -3.18730645e+03 -5.02131215e+04 -5.53631545e+03 -7.49005202e+03\n",
      " -5.79048705e+03 -2.72662505e+06 -2.37353678e+03 -3.65045748e+03\n",
      " -1.69318530e+06 -4.43160260e+03 -2.90218799e+03 -1.99192496e+04\n",
      " -4.07331196e+03 -1.98013189e+03 -3.03092877e+03 -3.49974583e+03\n",
      " -5.19865007e+03 -2.66128568e+03 -3.28446564e+03 -6.89474702e+03\n",
      " -2.14531041e+03 -3.63946011e+03 -3.43372011e+03 -3.65255782e+03]\n",
      "276883905.5323211\n",
      "[2.08586561e+04 1.21615268e+04 1.58189113e+04 1.53149985e+04\n",
      " 1.96667920e+04 3.09837843e+05 3.41744829e+04 4.62438727e+04\n",
      " 3.56838112e+04 1.71595819e+07 1.46139413e+04 2.25062024e+04\n",
      " 1.03053272e+07 2.73412666e+04 1.79349994e+04 1.22950252e+05\n",
      " 2.51422909e+04 1.22223784e+04 1.87079792e+04 2.15993810e+04\n",
      " 3.20943047e+04 1.63942906e+04 2.02692406e+04 4.30020085e+04\n",
      " 1.32530473e+04 2.24587950e+04 2.11932196e+04 2.25392120e+04]\n",
      "10773074777.413263\n",
      "[-1.29107109e+05 -7.53663931e+04 -9.80036828e+04 -9.48741437e+04\n",
      " -1.21846453e+05 -1.91970385e+06 -2.11789630e+05 -2.86622574e+05\n",
      " -2.20911968e+05 -1.07614000e+08 -9.04273775e+04 -1.39377752e+05\n",
      " -6.33288540e+07 -1.69390168e+05 -1.11226217e+05 -7.61941092e+05\n",
      " -1.55805234e+05 -7.57438698e+04 -1.15932464e+05 -1.33842982e+05\n",
      " -1.98913272e+05 -1.01470812e+05 -1.25594582e+05 -2.68204627e+05\n",
      " -8.21712050e+04 -1.39157972e+05 -1.31331044e+05 -1.39654729e+05]\n",
      "419292123994.8508\n",
      "[8.01687420e+05 4.68330521e+05 6.08892398e+05 5.89420314e+05\n",
      " 7.57048333e+05 1.19276472e+07 1.31609483e+06 1.78125186e+06\n",
      " 1.37191706e+06 6.73488218e+08 5.61402733e+05 8.65736072e+05\n",
      " 3.91499176e+08 1.05242088e+06 6.91469378e+05 4.73474576e+06\n",
      " 9.68168207e+05 4.70677219e+05 7.20399974e+05 8.31666179e+05\n",
      " 1.23613666e+06 6.30071869e+05 7.80390378e+05 1.67306266e+06\n",
      " 5.10770029e+05 8.64652406e+05 8.16076178e+05 8.67733239e+05]\n",
      "16320832308071.34\n",
      "[-4.98748976e+06 -2.91489131e+06 -3.78934798e+06 -3.66805947e+06\n",
      " -4.71144830e+06 -7.42321344e+07 -8.19146917e+06 -1.10871396e+07\n",
      " -8.53565445e+06 -4.20973445e+09 -3.49223155e+06 -5.38698084e+06\n",
      " -2.42908738e+09 -6.54960536e+06 -4.30485145e+06 -2.94691110e+07\n",
      " -6.02582996e+06 -2.92950144e+06 -4.48373332e+06 -5.17614073e+06\n",
      " -7.69401939e+06 -3.91979091e+06 -4.85692505e+06 -1.04373194e+07\n",
      " -3.17961222e+06 -5.38129208e+06 -5.07918088e+06 -5.40044456e+06]\n",
      "635309514315469.8\n",
      "[3.10640506e+07 1.81599492e+07 2.36063609e+07 2.28503735e+07\n",
      " 2.93510229e+07 4.62449710e+08 5.10336811e+07 6.90758741e+07\n",
      " 5.31657867e+07 2.62941419e+10 2.17495316e+07 3.35560969e+07\n",
      " 1.51048282e+10 4.08019347e+07 2.68237695e+07 1.83594453e+08\n",
      " 3.75410884e+07 1.82509867e+07 2.79337832e+07 3.22470949e+07\n",
      " 4.79353279e+07 2.44138664e+07 3.02580816e+07 6.51157202e+07\n",
      " 1.98113421e+07 3.35246184e+07 3.16433007e+07 3.36438545e+07]\n"
     ]
    }
   ],
   "source": [
    "gamma = 0.00001\n",
    "max_iters = 10\n",
    "w_initial = np.zeros(cleaned_x_train.shape[1])\n",
    "\n",
    "w, loss = mean_squared_error_gd(y_train, cleaned_x_train, w_initial, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "635309514315469.8"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean squared error sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.00001\n",
    "max_iters = 100\n",
    "w_initial = np.zeros(cleaned_x_train.shape[1])\n",
    "\n",
    "w, loss = mean_squared_error_sgd(y_train, cleaned_x_train, w_initial, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Least squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, loss = least_squares(y_train, cleaned_x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "print(len(label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.29695599e+01 2.51145669e+01 3.26484113e+01 3.16032914e+01\n",
      " 4.05931422e+01 6.39574453e+02 7.05774129e+01 9.55269539e+01\n",
      " 7.35393282e+01 3.62905491e+04 3.00867864e+01 4.64124920e+01\n",
      " 2.09206344e+04 5.64303677e+01 3.70916489e+01 2.53904536e+02\n",
      " 5.19182016e+01 2.52404526e+01 3.86315896e+01 4.45972177e+01\n",
      " 6.62916371e+01 3.37707816e+01 4.18467877e+01 8.99539567e+01\n",
      " 2.73960169e+01 4.63646235e+01 4.37618949e+01 4.65296156e+01]\n",
      "635309514315469.8\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "print(w)\n",
    "print(loss)\n",
    "print(len(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up x test\n",
    "\n",
    "cleaned_x_test = clean_data(labels, label_list, x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109379, 29)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_test = build_poly(cleaned_x_test,degree)\n",
    "poly_test.shape\n",
    "                                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# notes for next one working on this lol\n",
    "\n",
    "ridge -> build poly -> predict label: Ca marche mais pas très bons résultats (mieux si tu montes le degré mais tres bas F1)\n",
    "\n",
    "least squares -> predict label : marche pas avec build poly pck pas les bonnes dims (build poly rajoute une colonne, donc impossible de faire data@weight) Ca marche sans, mais on a que 1 valeur a 1, le reste a -1 (et ya pas de params a changer) F1 SCORE 0.000 ACCURACY 0.912\n",
    "\n",
    "mean squared gd -> (same thing pour build poly) les valeurs sont fucked up mdr [1.13497280e+79 1.72690226e+79 3.20689183e+78 ... 1.36781180e+78 1.99141883e+78 1.76606508e+78] c'est du 10^78 a peu pres, donc ya tout qui fini par etre a 1 et rien a -1 \n",
    "\n",
    "mean squared sgd -> same as gd mais on est plutot dans du 10^14, et que des negatifs\n",
    "\n",
    "J'ai aussi tenté ridge en filtrant les données d'une autre manière, aka juste prendre les colonnes qui ont plus que 70% de données (par rapport aux nan) et ca me donne des meilleurs résultats... snif snif donc F1 SCORE 0.139 ACCURACY 0.837 Après j'ai rien clean up or anything donc c'est un peu ridicule genre ya toutes les valeurs d'exceptions encore (en vrai j'ai aucune idée de pourquoi ca a marché ??? Pck j'ai pas enlevé les nan ?? Donc ca a du bader hahahaha)\n",
    "\n",
    "Si je mets 1000 max_iters ca overflow error, donc j'ai laissé 100, a tester avec 500 par exemple\n",
    "\n",
    "Idées: Peut être que normalizer les data ca change qqch mour les deux mean squares ? \n",
    "\n",
    "Questions TA:\n",
    "- regarder nos logisitc methods\n",
    "- pk ca marche pas lol\n",
    "- est - ce que c'est une bonne idée la manière dont on fait ou est-ce qu'il nous faut beaucoup plus de colonnes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### noms des variables et valeurs utilisées\n",
    "\n",
    "- cleaned_x_train/test : data nettoyée avec nos 28 colonnes choisies\n",
    "- x_train/test_filtered : data avec enlevé ceux avec moins de 70% de donnees\n",
    "- x_train_1 etc: c'est x_train cleaned de la meme manière mais ils sont divisé en test/train pour nous meme faire cross validation\n",
    "\n",
    "- degres: pour ridge utiliser un grand chiffre, pour le reste utiliser 1 (bah en fait c'est juste pour build poly donc pas utiliser (je crois, j'ai pas trouvé de valuers qui marche))\n",
    "\n",
    "- max_iters: j'ai l'impression que plus je mets grand, plus mes y_pred sont grands (why??????) (avec 1, j'ai que des -1.3 environ, quand je mets 2 j'ai entre 1 et 20, quand je mets 100 j'ai 10^78 lol) Ca explique le overflow error quand je mets 1000 i guess\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.50522933e+18 1.70788021e+19 2.73299094e+18 ... 1.03292313e+18\n",
      " 1.66305793e+18 1.33766479e+18]\n"
     ]
    }
   ],
   "source": [
    "yp = predict_labels(w,cleaned_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(np.where(yp == 1)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSV Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_submission(test_ids,yp,\"outputs/ridge_degre25_200features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## let me do loops and stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (98440,197) and (28,) not aligned: 197 (dim 1) != 28 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/Julie/Desktop/EPFL/MA3/ML/ML_project1/run.ipynb Cellule 38\u001b[0m line \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Julie/Desktop/EPFL/MA3/ML/ML_project1/run.ipynb#X50sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m poly_test \u001b[39m=\u001b[39m build_poly(cleaned_x_test_1,\u001b[39m7\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Julie/Desktop/EPFL/MA3/ML/ML_project1/run.ipynb#X50sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m#predict\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Julie/Desktop/EPFL/MA3/ML/ML_project1/run.ipynb#X50sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m yp \u001b[39m=\u001b[39m predict_labels(w,poly_test)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Julie/Desktop/EPFL/MA3/ML/ML_project1/run.ipynb#X50sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# mesure accuracy\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Julie/Desktop/EPFL/MA3/ML/ML_project1/run.ipynb#X50sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m acc \u001b[39m=\u001b[39m measure_accuracy(y_test_1, yp)\n",
      "File \u001b[0;32m~/Desktop/EPFL/MA3/ML/ML_project1/helpers.py:408\u001b[0m, in \u001b[0;36mpredict_labels\u001b[0;34m(weights, data)\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict_labels\u001b[39m(weights, data):\n\u001b[1;32m    407\u001b[0m     \u001b[39m\"\"\"Generates class predictions given weights, and a test data matrix\"\"\"\u001b[39;00m\n\u001b[0;32m--> 408\u001b[0m     y_pred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mdot(data, weights)\n\u001b[1;32m    409\u001b[0m     \u001b[39mprint\u001b[39m((y_pred))\n\u001b[1;32m    410\u001b[0m     y_pred[np\u001b[39m.\u001b[39mwhere(y_pred \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m)] \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (98440,197) and (28,) not aligned: 197 (dim 1) != 28 (dim 0)"
     ]
    }
   ],
   "source": [
    "N = 10\n",
    "gammas = np.linspace(0.0001, 0.1, N)\n",
    "max_iters_arr = np.linspace(1, 200, N)\n",
    "initial_w = np.zeros(cleaned_x_train_1.shape[1])\n",
    "accs = []\n",
    "f1s = []\n",
    "\n",
    "for gamma in gammas:\n",
    "    # train\n",
    "    w, loss = ridge_regression(y_train_1, cleaned_x_train_1, gamma)\n",
    "    poly_test = build_poly(cleaned_x_test_1,7)\n",
    "\n",
    "    #predict\n",
    "    yp = predict_labels(w,poly_test)\n",
    "\n",
    "    # mesure accuracy\n",
    "    acc = measure_accuracy(y_test_1, yp)\n",
    "    f1 = measure_f1_score(y_test_1, yp)\n",
    "    accs.append(acc)\n",
    "    f1s.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08906948394961398, 0.08906948394961398, 0.08906948394961398, 0.08906948394961398, 0.08906948394961398, 0.08906948394961398, 0.08906948394961398, 0.08906948394961398, 0.08906948394961398, 0.08906948394961398]\n",
      "[0.16356988284456384, 0.16356988284456384, 0.16356988284456384, 0.16356988284456384, 0.16356988284456384, 0.16356988284456384, 0.16356988284456384, 0.16356988284456384, 0.16356988284456384, 0.16356988284456384]\n"
     ]
    }
   ],
   "source": [
    "print(accs)\n",
    "print(f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(gammas,accs,\"r\")\n",
    "plt.plot(gammas, f1s, \"b\")\n",
    "\n",
    "plt.title(\"Mean squared error gd accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.xlabel(\"Gamma\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
