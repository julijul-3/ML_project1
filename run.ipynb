{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import *\n",
    "from implementations import *\n",
    "\n",
    "# from test_utils import test\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run de A a Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading  data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, train_ids, test_ids = load_csv_data(\"dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.genfromtxt(\"dataset/x_test.csv\", delimiter=\",\", dtype = str, max_rows=1)\n",
    "labels = np.delete(labels,0) # delete the label 'id' as we dont have it in x_train and x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the high number of features with all different exceptions values and linearity, we decided to select manually the features we found relevant. The list below is the name of the feature, the exception values that we have to remplace, and wheter we remplace by majority (True) or by the mean (False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = [(\"MSCODE\", [], True),\n",
    "            (\"_HCVU651\", [9], True),\n",
    "            (\"_RFHYPE5\", [9], True),\n",
    "            (\"_RFCHOL\", [9], True),\n",
    "            (\"_RACE\",[9], True),\n",
    "            (\"_BMI5\",[], False),\n",
    "            (\"_EDUCAG\",[9], True),\n",
    "            (\"_INCOMG\",[9], True),\n",
    "            (\"_DRNKWEK\",[99900], False),\n",
    "            (\"_SMOKER3\",[9], True),\n",
    "            (\"_FRUTSUM\",[], False),\n",
    "            (\"_VEGESUM\",[], False),\n",
    "            (\"PA1MIN_\",[], False),\n",
    "            (\"GENHLTH\",[7,9], False),\n",
    "            (\"CHECKUP1\",[7,9], False),\n",
    "            (\"MENTHLTH\",[88, 77, 99], False),\n",
    "            (\"BPHIGH4\",[7,9], True),\n",
    "            (\"BPMEDS\",[7,9], True),\n",
    "            (\"TOLDHI2\",[7,9], True),\n",
    "            (\"CHCOCNCR\",[7,8,9], True),\n",
    "            (\"DIABETE3\",[7,8,9], True),\n",
    "            (\"SEX\",[], True),\n",
    "            (\"QLACTLM2\",[7,9], True),\n",
    "            (\"AVEDRNK2\",[77, 99], False),\n",
    "            (\"EXERANY2\",[7,9], True),\n",
    "            (\"SHINGLE2\", [7,9], True),\n",
    "            (\"LMTJOIN3\", [7,9], True),\n",
    "            (\"CVDASPRN\", [7,9], True)\n",
    "            ]\n",
    "\n",
    "\n",
    "cleaned_x_train = clean_data(labels, label_list, x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 2., 2., 2.],\n",
       "       [5., 1., 2., ..., 2., 2., 2.],\n",
       "       [1., 1., 1., ..., 2., 2., 2.],\n",
       "       ...,\n",
       "       [1., 1., 1., ..., 2., 2., 2.],\n",
       "       [5., 1., 1., ..., 2., 2., 2.],\n",
       "       [1., 1., 2., ..., 2., 2., 2.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then check that we have enough data in our features, i.e. there is not an exagerated amount of nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# want to see which labels are way to small\n",
    "\n",
    "for label in label_list:\n",
    "    l, _, _ = label\n",
    "    id = np.where(labels == l)[0][0]\n",
    "    x = x_train[:][id]\n",
    "\n",
    "    # Count the number of NaN values\n",
    "    nans= np.count_nonzero(np.isnan(x))\n",
    "    nan_perc = nans/len(x) *100\n",
    "    #print(nan_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check that our features are uncorrelated as it would lead to less good results, but we saw that the uncorrelated data had the same dimension as the original cleaned data, so no changes were made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328135, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(328135, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_matrix = np.corrcoef(cleaned_x_train, rowvar=False)\n",
    "correlation_threshold = 0.7\n",
    "uncorrelated_indices = np.where(np.abs(correlation_matrix) < correlation_threshold)\n",
    "uncorrelated_columns = np.unique(uncorrelated_indices[1])\n",
    "uncorrelated_data = cleaned_x_train[:, uncorrelated_columns]\n",
    "print(uncorrelated_data.shape)\n",
    "cleaned_x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "We here choose which function we want to train our data with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(701,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_ = 0.0001\n",
    "degree = 25\n",
    "## tx is cleaned data \n",
    "poly = build_poly(cleaned_x_train,degree)\n",
    "w , loss = ridge_regression(y_train,poly,lambda_)\n",
    "w.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean squared errors gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.0001\n",
    "max_iters = 1000\n",
    "w_initial = np.zeros(cleaned_x_train.shape[1])\n",
    "\n",
    "w, loss = mean_squared_error_gd(y_train, cleaned_x_train, w_initial, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4940363288172364"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean squared error sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.00001\n",
    "max_iters = 100\n",
    "w_initial = np.zeros(cleaned_x_train.shape[1])\n",
    "\n",
    "w, loss = mean_squared_error_sgd(y_train, cleaned_x_train, w_initial, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Least squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, loss = least_squares(y_train, cleaned_x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\duval\\Documents\\GitHub\\ML_project1\\helpers.py:96: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0 / (1 + np.exp(-t))\n",
      "c:\\Users\\duval\\Documents\\GitHub\\ML_project1\\helpers.py:115: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -np.mean(y * np.log(pred) + (1 - y) * np.log(1 - pred))\n",
      "c:\\Users\\duval\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\_methods.py:180: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n"
     ]
    }
   ],
   "source": [
    "max_iters = 1000\n",
    "gamma = 0.01\n",
    "w_initial = np.zeros(cleaned_x_train.shape[1])\n",
    "w, loss = logistic_regression(y_train, cleaned_x_train, w_initial, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reg logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iters = 1000\n",
    "gamma = 0.01\n",
    "lambda_ = 0.001\n",
    "w_initial = np.zeros(cleaned_x_train.shape[1])\n",
    "w, loss = reg_logistic_regression(y_train, cleaned_x_train, lambda_, w_initial, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-14.79804473  -8.77238717 -10.84327554 -10.59781838 -15.70345826\n",
      "   0.29566508 -24.45667781 -33.11180685   2.47068432 -27.67066015\n",
      "   0.12757138  -0.13770024   0.26736939   1.39737351  -0.37300463\n",
      "   0.35823878 -19.13955423  -8.70922062 -13.88738712 -15.65980897\n",
      " -23.11047421 -13.06839543 -14.80123112  -0.06041344  -9.95308042\n",
      " -16.19699181 -15.39133796 -16.24954041]\n",
      "nan\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "#print(w)\n",
    "#print(loss)\n",
    "#print(len(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "\n",
    "We then test our data, cleaning the test dataset and building predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up x test\n",
    "\n",
    "cleaned_x_test = clean_data(labels, label_list, x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109379, 701)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only used for ridge\n",
    "poly_test = build_poly(cleaned_x_test,degree)\n",
    "poly_test.shape\n",
    "                                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction\n",
    "\n",
    "Use the correct prediction function depending on which train method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp = predict_labels_mse(w,cleaned_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp = predict_labels_logistic(w,cleaned_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(np.where(y_pred == 1)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSV Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'outputs/ridge_degre25_200features.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\duval\\Documents\\GitHub\\ML_project1\\run.ipynb Cell 45\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/duval/Documents/GitHub/ML_project1/run.ipynb#X62sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m create_csv_submission(test_ids,yp,\u001b[39m\"\u001b[39;49m\u001b[39moutputs/ridge_degre25_200features.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\duval\\Documents\\GitHub\\ML_project1\\helpers.py:236\u001b[0m, in \u001b[0;36mcreate_csv_submission\u001b[1;34m(ids, y_pred, name)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(i \u001b[39min\u001b[39;00m [\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m y_pred):\n\u001b[0;32m    234\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39my_pred can only contain values -1, 1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 236\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(name, \u001b[39m\"\u001b[39;49m\u001b[39mw\u001b[39;49m\u001b[39m\"\u001b[39;49m, newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m csvfile:\n\u001b[0;32m    237\u001b[0m     fieldnames \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mId\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mPrediction\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    238\u001b[0m     writer \u001b[39m=\u001b[39m csv\u001b[39m.\u001b[39mDictWriter(csvfile, delimiter\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m, fieldnames\u001b[39m=\u001b[39mfieldnames)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'outputs/ridge_degre25_200features.csv'"
     ]
    }
   ],
   "source": [
    "create_csv_submission(test_ids,yp,\"outputs/ridge_degre25_200features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split for our own cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####read me or smth\n",
    "\n",
    "- N c'est le nombre de loops\n",
    "- pour l'instant ca loop sur gamma mais si tu veux changer de param tu peux le modifier\n",
    "- initial_w, accs et f1s pas besoin de changer\n",
    "\n",
    "Utilise pas ridge i guess tfacon c'est pas celle qui nous interesse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_1, y_train_1, x_test_1, y_test_1 = split_train_test(y_train, x_train, 0.7)\n",
    "cleaned_x_train_1 = clean_data(labels, label_list, x_train_1)\n",
    "cleaned_x_test_1 = clean_data(labels, label_list, x_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.47233381 0.46608495 0.47101033 ... 0.47411245 0.46855243 0.46914328]\n",
      "[0.44542355 0.43319689 0.44283057 ... 0.4489128  0.43801891 0.43917371]\n",
      "[0.41939077 0.40156703 0.41560183 ... 0.42449905 0.40858212 0.41026345]\n",
      "[0.39432994 0.37137307 0.3894337  ... 0.4009473  0.38038336 0.3825459 ]\n",
      "[0.37031003 0.34274114 0.36440584 ... 0.37831328 0.35352438 0.35611743]\n",
      "[0.34737691 0.31575001 0.34057075 ... 0.35663426 0.32807076 0.33104061]\n",
      "[0.32555608 0.29043699 0.31795697 ... 0.33593136 0.30405622 0.30734819]\n",
      "[0.30485572 0.2668045  0.29657265 ... 0.3162119  0.28148752 0.28504767]\n",
      "[0.28526953 0.24482673 0.27640905 ... 0.29747167 0.26034923 0.26412568]\n",
      "[0.26677958 0.22445599 0.25744384 ... 0.27969709 0.24060845 0.24455233]\n",
      "[0.24935878 0.20562842 0.23964418 ... 0.26286719 0.22221891 0.22628507]\n",
      "[0.23297308 0.18826895 0.22296932 ... 0.24695528 0.20512472 0.2092721 ]\n",
      "[0.21758342 0.17229536 0.20737291 ... 0.23193043 0.18926343 0.19345522]\n",
      "[0.20314729 0.15762171 0.19280488 ... 0.21775875 0.1745686  0.17877229]\n",
      "[0.18962002 0.14416086 0.17921302 ... 0.20440439 0.16097187 0.16515912]\n",
      "[0.17695593 0.13182655 0.1665442  ... 0.19183039 0.14840459 0.152551  ]\n",
      "[0.16510908 0.12053482 0.15474535 ... 0.17999938 0.13679901 0.14088392]\n",
      "[0.15403397 0.11020502 0.14376425 ... 0.16887406 0.12608926 0.13009536]\n",
      "[0.14368605 0.10076057 0.13355003 ... 0.15841766 0.11621192 0.12012503]\n",
      "[0.13402205 0.09212929 0.12405359 ... 0.14859423 0.10710651 0.1109152 ]\n"
     ]
    }
   ],
   "source": [
    "N = 20\n",
    "max_iters = 1000\n",
    "gammas = np.linspace(0.00000001, 0.1, N)\n",
    "initial_w = np.zeros(cleaned_x_train_1.shape[1])\n",
    "accs = []\n",
    "f1s = []\n",
    "\n",
    "for gamma in gammas:\n",
    "    # train\n",
    "    # choisi la methode de train qui t'interesse\n",
    "    #w, loss = mean_squared_error_gd(y_train_1, cleaned_x_train_1, initial_w, max_iters, gamma)\n",
    "    w, loss = reg_logistic_regression(y_train_1, cleaned_x_train_1, gamma, initial_w, max_iters, 0.00001)\n",
    "    #predict \n",
    "    # choisi la methode de test qui t'interresse (commente l'autre)\n",
    "    #yp = predict_labels_mse(w,cleaned_x_test_1)\n",
    "    yp = predict_labels_logistic(w, cleaned_x_test_1)\n",
    "\n",
    "    # mesure accuracy\n",
    "    acc = measure_accuracy(y_test_1, yp)\n",
    "    f1 = measure_f1_score(y_test_1, yp)\n",
    "    accs.append(acc)\n",
    "    f1s.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.910930516050386, 0.910930516050386, 0.910930516050386, 0.910930516050386, 0.910930516050386, 0.910930516050386, 0.910930516050386, 0.910930516050386, 0.910930516050386, 0.910930516050386, 0.910930516050386, 0.910930516050386, 0.910930516050386, 0.910930516050386, 0.910930516050386, 0.910930516050386, 0.910930516050386, 0.910930516050386, 0.910930516050386, 0.910930516050386]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print(accs)\n",
    "print(f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tu peux plot tes tableaux ici ca fait ton parametre x accuracies et f1 \n",
    "# (change le gammas si t'as changé de param la haut)\n",
    "plt.plot(gammas,accs,\"r\")\n",
    "plt.plot(gammas, f1s, \"b\")\n",
    "\n",
    "plt.title(\"REg logistic regression accuracy/f1\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.xlabel(\"gammas\")\n",
    "plt.ylabel(\"Accuracy and F1 (%)\")\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9035757822023568"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing which method is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy ridge:\n",
      "0.9035757822023568\n",
      "f1 ridge:\n",
      "0.21084137013634852\n",
      "accuracy mse gd:\n",
      "0.910930516050386\n",
      "f1 mse gd:\n",
      "0.0\n",
      "accuracy mse sgd:\n",
      "0.9109101991060544\n",
      "f1 mse sgd:\n",
      "0.0013664313368253246\n",
      "accuracy least squares:\n",
      "0.910930516050386\n",
      "f1 mse least squares:\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Julie/Desktop/EPFL/MA3/ML/ML_project1/helpers.py:96: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0 / (1 + np.exp(-t))\n",
      "/Users/Julie/Desktop/EPFL/MA3/ML/ML_project1/helpers.py:115: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -np.mean(y * np.log(pred) + (1 - y) * np.log(1 - pred))\n",
      "/Users/Julie/opt/anaconda3/envs/project1-grading/lib/python3.9/site-packages/numpy/core/_methods.py:180: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.66785941e-306 0.00000000e+000 0.00000000e+000 ... 1.21675072e-285\n",
      " 0.00000000e+000 0.00000000e+000]\n",
      "accuracy logistic reg:\n",
      "0.910930516050386\n",
      "f1 mse logistic reg:\n",
      "0.0\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "accuracy reg logistic reg:\n",
      "0.910930516050386\n",
      "f1 mse reg logistic reg:\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "gamma = 0.01\n",
    "lambda_ = 0.0000001\n",
    "max_iters = 1000\n",
    "degree = 9\n",
    "initial_w = np.zeros(cleaned_x_train_1.shape[1])\n",
    "\n",
    "# ridge\n",
    "poly_train = build_poly(cleaned_x_train_1, degree)\n",
    "w, loss = ridge_regression(y_train_1, poly_train, lambda_)\n",
    "poly_test = build_poly(cleaned_x_test_1, degree)\n",
    "yp = predict_labels_mse(w, poly_test)\n",
    "\n",
    "print(\"accuracy ridge:\")\n",
    "accuracy = measure_accuracy(y_test_1, yp)\n",
    "print(accuracy)\n",
    "print(\"f1 ridge:\")\n",
    "f1 = measure_f1_score(y_test_1, yp)\n",
    "print(f1)\n",
    "\n",
    "# mse gd\n",
    "w, loss = mean_squared_error_gd(y_train_1, cleaned_x_train_1, initial_w, max_iters, gamma)\n",
    "yp = predict_labels_mse(w, cleaned_x_test_1)\n",
    "\n",
    "print(\"accuracy mse gd:\")\n",
    "accuracy = measure_accuracy(y_test_1, yp)\n",
    "print(accuracy)\n",
    "print(\"f1 mse gd:\")\n",
    "f1 = measure_f1_score(y_test_1, yp)\n",
    "print(f1)\n",
    "\n",
    "# mse sgd\n",
    "w, loss = mean_squared_error_sgd(y_train_1, cleaned_x_train_1, initial_w, max_iters, gamma)\n",
    "yp = predict_labels_mse(w, cleaned_x_test_1)\n",
    "\n",
    "print(\"accuracy mse sgd:\")\n",
    "accuracy = measure_accuracy(y_test_1, yp)\n",
    "print(accuracy)\n",
    "print(\"f1 mse sgd:\")\n",
    "f1 = measure_f1_score(y_test_1, yp)\n",
    "print(f1)\n",
    "\n",
    "# mse sgd\n",
    "w, loss = least_squares(y_train_1, cleaned_x_train_1)\n",
    "yp = predict_labels_mse(w, cleaned_x_test_1)\n",
    "\n",
    "print(\"accuracy least squares:\")\n",
    "accuracy = measure_accuracy(y_test_1, yp)\n",
    "print(accuracy)\n",
    "print(\"f1 mse least squares:\")\n",
    "f1 = measure_f1_score(y_test_1, yp)\n",
    "print(f1)\n",
    "\n",
    "# logistic reg\n",
    "w, loss = logistic_regression(y_train_1, cleaned_x_train_1, initial_w, max_iters, gamma)\n",
    "yp = predict_labels_logistic(w, cleaned_x_test_1)\n",
    "\n",
    "print(\"accuracy logistic reg:\")\n",
    "accuracy = measure_accuracy(y_test_1, yp)\n",
    "print(accuracy)\n",
    "print(\"f1 mse logistic reg:\")\n",
    "f1 = measure_f1_score(y_test_1, yp)\n",
    "print(f1)\n",
    "\n",
    "# logistic reg\n",
    "w, loss = reg_logistic_regression(y_train_1, cleaned_x_train_1, lambda_, initial_w, max_iters, gamma)\n",
    "yp = predict_labels_logistic(w, cleaned_x_test_1)\n",
    "\n",
    "print(\"accuracy reg logistic reg:\")\n",
    "accuracy = measure_accuracy(y_test_1, yp)\n",
    "print(accuracy)\n",
    "print(\"f1 mse reg logistic reg:\")\n",
    "f1 = measure_f1_score(y_test_1, yp)\n",
    "print(f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamdas = 0.0000001\n",
    "accs = []\n",
    "f1s = []\n",
    "degrees = range(25)\n",
    "for deg in degrees:\n",
    "\n",
    "    # ridge\n",
    "    poly_train = build_poly(cleaned_x_train_1, deg)\n",
    "    w, loss = ridge_regression(y_train_1, poly_train, lamdas)\n",
    "    poly_test = build_poly(cleaned_x_test_1, deg)\n",
    "    yp = predict_labels_mse(w, poly_test)\n",
    "\n",
    "    accuracy = measure_accuracy(y_test_1, yp)\n",
    "    f1 = measure_f1_score(y_test_1, yp)\n",
    "    accs.append(accuracy)\n",
    "    f1s.append(f1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
