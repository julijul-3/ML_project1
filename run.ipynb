{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import *\n",
    "from implementations import *\n",
    "\n",
    "# from test_utils import test\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run de A a Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading  data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, train_ids, test_ids = load_csv_data(\"dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.genfromtxt(\"dataset/x_test.csv\", delimiter=\",\", dtype = str, max_rows=1)\n",
    "labels = np.delete(labels,0) # delete the label 'id' as we dont have it in x_train and x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the high number of features with all different exceptions values and linearity, we decided to select manually the features we found relevant. The list below is the name of the feature, the exception values that we have to remplace, and wheter we remplace by majority (True) or by the mean (False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = [(\"MSCODE\", [], True),\n",
    "            (\"_HCVU651\", [9], True),\n",
    "            (\"_RFHYPE5\", [9], True),\n",
    "            (\"_RFCHOL\", [9], True),\n",
    "            (\"_RACE\",[9], True),\n",
    "            (\"_BMI5\",[], False),\n",
    "            (\"_EDUCAG\",[9], True),\n",
    "            (\"_INCOMG\",[9], True),\n",
    "            (\"_DRNKWEK\",[99900], False),\n",
    "            (\"_SMOKER3\",[9], True),\n",
    "            (\"_FRUTSUM\",[], False),\n",
    "            (\"_VEGESUM\",[], False),\n",
    "            (\"PA1MIN_\",[], False),\n",
    "            (\"GENHLTH\",[7,9], False),\n",
    "            (\"CHECKUP1\",[7,9], False),\n",
    "            (\"MENTHLTH\",[88, 77, 99], False),\n",
    "            (\"BPHIGH4\",[7,9], True),\n",
    "            (\"BPMEDS\",[7,9], True),\n",
    "            (\"TOLDHI2\",[7,9], True),\n",
    "            (\"CHCOCNCR\",[7,8,9], True),\n",
    "            (\"DIABETE3\",[7,8,9], True),\n",
    "            (\"SEX\",[], True),\n",
    "            (\"QLACTLM2\",[7,9], True),\n",
    "            (\"AVEDRNK2\",[77, 99], False),\n",
    "            (\"EXERANY2\",[7,9], True),\n",
    "            (\"SHINGLE2\", [7,9], True),\n",
    "            (\"LMTJOIN3\", [7,9], True),\n",
    "            (\"CVDASPRN\", [7,9], True)\n",
    "            ]\n",
    "\n",
    "#jai retirer #(\"_DRNKWEK\",[99900], True),\n",
    "\n",
    "\n",
    "# label_list = [\n",
    "#             (\"_RFCHOL\", [9], True),\n",
    "#             (\"_SMOKER3\",[9], True),\n",
    "#             (\"_DRNKWEK\",[99900], False),\n",
    "#             (\"LMTJOIN3\", [7,9], True)\n",
    "#             ]\n",
    "\n",
    "cleaned_x_train = clean_data(labels, label_list, x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  1.        , -0.67754031,  2.        ],\n",
       "       [ 1.        ,  1.        , -0.67754031,  2.        ],\n",
       "       [ 2.        ,  3.        , -0.55759541,  2.        ],\n",
       "       ...,\n",
       "       [ 2.        ,  4.        , -0.67754031,  2.        ],\n",
       "       [ 1.        ,  4.        , -0.67754031,  2.        ],\n",
       "       [ 1.        ,  4.        , -0.67754031,  2.        ]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = np.corrcoef(cleaned_x_train, rowvar=False)\n",
    "\n",
    "# Define a correlation threshold (for example, 0.7)\n",
    "correlation_threshold = 0.7\n",
    "\n",
    "# Find the indices of uncorrelated columns\n",
    "uncorrelated_indices = np.where(np.abs(correlation_matrix) < correlation_threshold)\n",
    "\n",
    "# Get the unique column indices of uncorrelated variables\n",
    "uncorrelated_columns = np.unique(uncorrelated_indices[1])\n",
    "\n",
    "# Create a new dataset with uncorrelated variables\n",
    "uncorrelated_data = cleaned_x_train[:, uncorrelated_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ca change rien mdr ya tjr 28 dans le resultat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning in another way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.7  # You want to drop columns with > 50% NaNs\n",
    "column_count = x_train.shape[0]\n",
    "max_nan_count = threshold * column_count\n",
    "\n",
    "# Create a mask to identify columns with too many NaNs\n",
    "nan_mask = np.sum(np.isnan(x_train), axis=0) <= max_nan_count\n",
    "\n",
    "# Use the mask to select the columns with fewer NaNs\n",
    "x_train_filtered = x_train[:, nan_mask]\n",
    "x_test_filtered = x_test[:, nan_mask]\n",
    "\n",
    "# drop the "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split for our own cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_1, y_train_1, x_test_1, y_test_1 = split_train_test(y_train, x_train, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_x_train_1 = clean_data(labels, label_list, x_train_1)\n",
    "cleaned_x_test_1 = clean_data(labels, label_list, x_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.728971962616825\n",
      "46.728971962616825\n",
      "42.05607476635514\n",
      "32.398753894081\n",
      "38.940809968847354\n",
      "41.43302180685358\n",
      "44.54828660436137\n",
      "41.74454828660436\n",
      "41.74454828660436\n",
      "44.85981308411215\n",
      "50.155763239875384\n",
      "42.99065420560748\n",
      "46.10591900311526\n",
      "42.679127725856695\n",
      "36.7601246105919\n",
      "38.006230529595015\n",
      "43.925233644859816\n",
      "42.05607476635514\n",
      "50.77881619937694\n",
      "38.31775700934579\n",
      "39.56386292834891\n",
      "45.17133956386293\n",
      "30.8411214953271\n",
      "42.679127725856695\n",
      "42.36760124610592\n",
      "47.35202492211838\n",
      "52.024922118380054\n",
      "47.66355140186916\n"
     ]
    }
   ],
   "source": [
    "# want to see which labels are way to small\n",
    "\n",
    "for label in label_list:\n",
    "    l, _, _ = label\n",
    "    id = np.where(labels == l)[0][0]\n",
    "    x = x_train[:][id]\n",
    "\n",
    "    # Count the number of NaN values\n",
    "    nans= np.count_nonzero(np.isnan(x))\n",
    "    nan_perc = nans/len(x) *100\n",
    "    print(nan_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_ = 0.0001\n",
    "degree = 25\n",
    "## tx is cleaned data \n",
    "poly = build_poly(cleaned_x_train,degree)\n",
    "w , loss = ridge_regression(y_train,poly,lambda_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean squared errors gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4993986956091768\n",
      "[ 1.49149836  0.88424169  1.0928433   1.0681191   1.58292944 -0.02986482\n",
      "  2.46525858  3.33774353 -0.28192911  2.7891989  -0.09306784  0.01482692\n",
      " -0.01443856 -0.14114484  0.03767431 -0.03618673  1.92945536  0.87786506\n",
      "  1.39991229  1.5784889   2.32960102  1.31729361  1.49201084  0.00610009\n",
      "  1.00319927  1.63260981  1.55146231  1.63790869]\n",
      "\n",
      "0.49879843747016817\n",
      "[ 1.49013674  0.88347635  1.09185108  1.06714858  1.58153353 -0.02985285\n",
      "  2.46310775  3.33481885 -0.2816681   2.78675625 -0.09298484  0.01482112\n",
      " -0.0144288  -0.14111137  0.0376724  -0.03617254  1.92784717  0.87710155\n",
      "  1.3987285   1.5771201   2.32760551  1.3161583   1.49073496  0.00610813\n",
      "  1.00231259  1.63118609  1.55012586  1.63648116]\n",
      "\n",
      "0.49819922376146286\n",
      "[ 1.48877631  0.88271168  1.09085973  1.0661789   1.58013883 -0.02984088\n",
      "  2.4609588   3.33189672 -0.28140732  2.78431573 -0.09290191  0.01481534\n",
      " -0.01441905 -0.14107794  0.03767048 -0.03615837  1.92624037  0.87633872\n",
      "  1.39754575  1.57575248  2.32561173  1.31502397  1.4894602   0.00611617\n",
      "  1.00142668  1.62976361  1.54879058  1.63505488]\n",
      "\n",
      "0.4976010526647197\n",
      "[ 1.48741706  0.88194767  1.08986924  1.06521007  1.57874535 -0.02982893\n",
      "  2.45881171  3.32897713 -0.28114677  2.78187733 -0.09281906  0.01480955\n",
      " -0.01440931 -0.14104452  0.03766857 -0.03614422  1.92463498  0.87557654\n",
      "  1.39636402  1.57438606  2.32361969  1.31389064  1.48818655  0.00612421\n",
      "  1.00054154  1.62834237  1.54745646  1.63362983]\n",
      "\n",
      "0.49700392236476487\n",
      "[ 1.486059    0.88118433  1.08887962  1.06424208  1.57735308 -0.02981699\n",
      "  2.4566665   3.32606008 -0.28088645  2.77944106 -0.09273627  0.01480377\n",
      " -0.01439958 -0.14101114  0.03766666 -0.03613007  1.92303098  0.87481503\n",
      "  1.39518332  1.57302083  2.32162938  1.31275829  1.486914    0.00613223\n",
      "  0.99965717  1.62692237  1.54612351  1.63220603]\n",
      "\n",
      "0.4964078310495828\n",
      "[ 1.48470213  0.88042165  1.08789086  1.06327494  1.57596203 -0.02980505\n",
      "  2.45452316  3.32314558 -0.28062635  2.77700691 -0.09265356  0.014798\n",
      " -0.01438985 -0.14097779  0.03766475 -0.03611594  1.92142837  0.87405419\n",
      "  1.39400365  1.57165679  2.3196408   1.31162693  1.48564257  0.00614025\n",
      "  0.99877357  1.6255036   1.54479171  1.63078346]\n",
      "\n",
      "0.4958127769103141\n",
      "[ 1.48334644  0.87965964  1.08690296  1.06230864  1.57457218 -0.02979313\n",
      "  2.45238168  3.32023361 -0.28036648  2.77457487 -0.09257092  0.01479223\n",
      " -0.01438014 -0.14094446  0.03766284 -0.03610181  1.91982716  0.87329401\n",
      "  1.392825    1.57029393  2.31765396  1.31049655  1.48437224  0.00614826\n",
      "  0.99789074  1.62408607  1.54346108  1.62936214]\n",
      "\n",
      "0.49521875814124805\n",
      "[ 1.48199193  0.87889829  1.08591592  1.06134318  1.57318355 -0.02978122\n",
      "  2.45024206  3.31732418 -0.28010683  2.77214496 -0.09248836  0.01478646\n",
      " -0.01437043 -0.14091116  0.03766093 -0.0360877   1.91822734  0.87253449\n",
      "  1.39164739  1.56893226  2.31566885  1.30936715  1.48310301  0.00615626\n",
      "  0.99700868  1.62266977  1.5421316   1.62794205]\n",
      "\n",
      "0.4946257729398182\n",
      "[ 1.4806386   0.8781376   1.08492975  1.06037857  1.57179613 -0.02976931\n",
      "  2.44810431  3.31441728 -0.27984741  2.76971716 -0.09240586  0.0147807\n",
      " -0.01436073 -0.14087789  0.03765903 -0.03607361  1.91662892  0.87177563\n",
      "  1.39047079  1.56757178  2.31368546  1.30823875  1.48183489  0.00616426\n",
      "  0.99612739  1.62125471  1.54080328  1.6265232 ]\n",
      "\n",
      "0.49403381950659553\n",
      "[ 1.47928645  0.87737758  1.08394443  1.05941479  1.57040991 -0.02975742\n",
      "  2.44596842  3.31151291 -0.27958822  2.76729148 -0.09232344  0.01477495\n",
      " -0.01435104 -0.14084464  0.03765712 -0.03605952  1.91503188  0.87101743\n",
      "  1.38929522  1.56621248  2.3117038   1.30711132  1.48056788  0.00617225\n",
      "  0.99524686  1.61984088  1.53947612  1.62510559]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gamma = 0.00001\n",
    "max_iters = 10\n",
    "w_initial = np.zeros(cleaned_x_train.shape[1])\n",
    "\n",
    "w, loss = mean_squared_error_gd(y_train, cleaned_x_train, w_initial, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "629861112644857.4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean squared error sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.00001\n",
    "max_iters = 100\n",
    "w_initial = np.zeros(cleaned_x_train.shape[1])\n",
    "\n",
    "w, loss = mean_squared_error_sgd(y_train, cleaned_x_train, w_initial, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Least squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, loss = least_squares(y_train, cleaned_x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\duval\\Documents\\GitHub\\ML_project1\\helpers.py:96: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0 / (1 + np.exp(-t))\n",
      "c:\\Users\\duval\\Documents\\GitHub\\ML_project1\\helpers.py:115: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -np.mean(y * np.log(pred) + (1 - y) * np.log(1 - pred))\n",
      "c:\\Users\\duval\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\_methods.py:180: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n"
     ]
    }
   ],
   "source": [
    "max_iters = 1000\n",
    "gamma = 0.01\n",
    "w_initial = np.zeros(cleaned_x_train.shape[1])\n",
    "w, loss = logistic_regression(y_train, cleaned_x_train, w_initial, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reg logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iters = 1000\n",
    "gamma = 0.01\n",
    "lambda_ = 0.001\n",
    "w_initial = np.zeros(cleaned_x_train.shape[1])\n",
    "w, loss = reg_logistic_regression(y_train, cleaned_x_train, lambda_, w_initial, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.47897652e+01 -8.76754527e+00 -1.08367742e+01 -1.05915697e+01\n",
      " -1.56953762e+01  2.95801575e-01 -2.44438059e+01 -3.30948043e+01\n",
      " -2.76559928e+01 -2.11760635e+03 -1.01348713e+01 -1.52940074e+01\n",
      " -3.06310683e+03  1.39774885e+00 -3.73020669e-01  3.58405166e-01\n",
      " -1.91299119e+01 -8.70438288e+00 -1.38800534e+01 -1.56512382e+01\n",
      " -2.30982424e+01 -1.30612860e+01 -1.47934087e+01 -6.03157743e-02\n",
      " -9.94737356e+00 -1.61880227e+01 -1.53830696e+01 -1.62405490e+01]\n",
      "nan\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "print(w)\n",
    "print(loss)\n",
    "print(len(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up x test\n",
    "\n",
    "cleaned_x_test = clean_data(labels, label_list, x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109379, 701)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_test = build_poly(cleaned_x_test,degree)\n",
    "poly_test.shape\n",
    "                                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# notes for next one working on this lol\n",
    "\n",
    "ridge -> build poly -> predict label: Ca marche mais pas très bons résultats (mieux si tu montes le degré mais tres bas F1)\n",
    "\n",
    "least squares -> predict label : marche pas avec build poly pck pas les bonnes dims (build poly rajoute une colonne, donc impossible de faire data@weight) Ca marche sans, mais on a que 1 valeur a 1, le reste a -1 (et ya pas de params a changer) F1 SCORE 0.000 ACCURACY 0.912\n",
    "\n",
    "mean squared gd -> (same thing pour build poly) les valeurs sont fucked up mdr [1.13497280e+79 1.72690226e+79 3.20689183e+78 ... 1.36781180e+78 1.99141883e+78 1.76606508e+78] c'est du 10^78 a peu pres, donc ya tout qui fini par etre a 1 et rien a -1 \n",
    "\n",
    "mean squared sgd -> same as gd mais on est plutot dans du 10^14, et que des negatifs\n",
    "\n",
    "J'ai aussi tenté ridge en filtrant les données d'une autre manière, aka juste prendre les colonnes qui ont plus que 70% de données (par rapport aux nan) et ca me donne des meilleurs résultats... snif snif donc F1 SCORE 0.139 ACCURACY 0.837 Après j'ai rien clean up or anything donc c'est un peu ridicule genre ya toutes les valeurs d'exceptions encore (en vrai j'ai aucune idée de pourquoi ca a marché ??? Pck j'ai pas enlevé les nan ?? Donc ca a du bader hahahaha)\n",
    "\n",
    "Si je mets 1000 max_iters ca overflow error, donc j'ai laissé 100, a tester avec 500 par exemple\n",
    "\n",
    "Idées: Peut être que normalizer les data ca change qqch mour les deux mean squares ? \n",
    "\n",
    "Questions TA:\n",
    "- regarder nos logisitc methods\n",
    "- pk ca marche pas lol\n",
    "- est - ce que c'est une bonne idée la manière dont on fait ou est-ce qu'il nous faut beaucoup plus de colonnes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### noms des variables et valeurs utilisées\n",
    "\n",
    "- cleaned_x_train/test : data nettoyée avec nos 28 colonnes choisies\n",
    "- x_train/test_filtered : data avec enlevé ceux avec moins de 70% de donnees\n",
    "- x_train_1 etc: c'est x_train cleaned de la meme manière mais ils sont divisé en test/train pour nous meme faire cross validation\n",
    "\n",
    "- degres: pour ridge utiliser un grand chiffre, pour le reste utiliser 1 (bah en fait c'est juste pour build poly donc pas utiliser (je crois, j'ai pas trouvé de valuers qui marche))\n",
    "\n",
    "- max_iters: j'ai l'impression que plus je mets grand, plus mes y_pred sont grands (why??????) (avec 1, j'ai que des -1.3 environ, quand je mets 2 j'ai entre 1 et 20, quand je mets 100 j'ai 10^78 lol) Ca explique le overflow error quand je mets 1000 i guess\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities: [0. 0. 0. ... 0. 0. 0.]\n",
      "Predictions: [0 0 0 ... 0 0 0]\n",
      "[-4595495.00023891 -3093328.17496262  -994191.04622787 ...\n",
      "  -552072.27699623  -651663.82208379  -711431.96741468]\n"
     ]
    }
   ],
   "source": [
    "# predict for logistic\n",
    "\n",
    "z = np.dot(cleaned_x_test, w)\n",
    "probabilities = sigmoid(z)\n",
    "\n",
    "# Make binary predictions using a threshold (e.g., 0.5)\n",
    "predictions = (probabilities >= 0.5).astype(int)\n",
    "\n",
    "print(\"Probabilities:\", probabilities)\n",
    "print(\"Predictions:\", predictions)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.07667651 -0.07756121 -0.07517545 ... -0.06903538 -0.0704128\n",
      " -0.07593806]\n"
     ]
    }
   ],
   "source": [
    "yp = predict_labels(w,cleaned_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(np.where(yp == 1)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSV Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'outputs/ridge_degre25_200features.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\duval\\Documents\\GitHub\\ML_project1\\run.ipynb Cell 45\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/duval/Documents/GitHub/ML_project1/run.ipynb#X62sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m create_csv_submission(test_ids,yp,\u001b[39m\"\u001b[39;49m\u001b[39moutputs/ridge_degre25_200features.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\duval\\Documents\\GitHub\\ML_project1\\helpers.py:236\u001b[0m, in \u001b[0;36mcreate_csv_submission\u001b[1;34m(ids, y_pred, name)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(i \u001b[39min\u001b[39;00m [\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m y_pred):\n\u001b[0;32m    234\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39my_pred can only contain values -1, 1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 236\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(name, \u001b[39m\"\u001b[39;49m\u001b[39mw\u001b[39;49m\u001b[39m\"\u001b[39;49m, newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m csvfile:\n\u001b[0;32m    237\u001b[0m     fieldnames \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mId\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mPrediction\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    238\u001b[0m     writer \u001b[39m=\u001b[39m csv\u001b[39m.\u001b[39mDictWriter(csvfile, delimiter\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m, fieldnames\u001b[39m=\u001b[39mfieldnames)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'outputs/ridge_degre25_200features.csv'"
     ]
    }
   ],
   "source": [
    "create_csv_submission(test_ids,yp,\"outputs/ridge_degre25_200features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## let me do loops and stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "mean_squared_error_gd() missing 2 required positional arguments: 'max_iters' and 'gamma'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\duval\\Documents\\GitHub\\ML_project1\\run.ipynb Cell 48\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/duval/Documents/GitHub/ML_project1/run.ipynb#Y104sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m f1s \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/duval/Documents/GitHub/ML_project1/run.ipynb#Y104sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m gamma \u001b[39min\u001b[39;00m gammas:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/duval/Documents/GitHub/ML_project1/run.ipynb#Y104sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39m# train\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/duval/Documents/GitHub/ML_project1/run.ipynb#Y104sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     w, loss \u001b[39m=\u001b[39m mean_squared_error_gd(y_train, cleaned_x_train, gamma)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/duval/Documents/GitHub/ML_project1/run.ipynb#Y104sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m#poly_test = build_poly(cleaned_x_test,7)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/duval/Documents/GitHub/ML_project1/run.ipynb#Y104sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/duval/Documents/GitHub/ML_project1/run.ipynb#Y104sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m#predict\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/duval/Documents/GitHub/ML_project1/run.ipynb#Y104sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39m# si pas ridge met cleaned_x_test_1 a la place de poly_test\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/duval/Documents/GitHub/ML_project1/run.ipynb#Y104sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     yp \u001b[39m=\u001b[39m predict_labels(w,cleaned_x_test)\n",
      "\u001b[1;31mTypeError\u001b[0m: mean_squared_error_gd() missing 2 required positional arguments: 'max_iters' and 'gamma'"
     ]
    }
   ],
   "source": [
    "N = 10\n",
    "gammas = np.linspace(0.0001, 0.1, N)\n",
    "max_iters_arr = np.linspace(1, 200, N)\n",
    "initial_w = np.zeros(cleaned_x_train_1.shape[1])\n",
    "accs = []\n",
    "f1s = []\n",
    "\n",
    "for gamma in gammas:\n",
    "    # train\n",
    "    w, loss = mean_squared_error_gd(y_train, cleaned_x_train, gamma)\n",
    "    #poly_test = build_poly(cleaned_x_test,7)\n",
    "\n",
    "    #predict\n",
    "    # si pas ridge met cleaned_x_test_1 a la place de poly_test\n",
    "    yp = predict_labels(w,cleaned_x_test)\n",
    "\n",
    "    # mesure accuracy\n",
    "    acc = measure_accuracy(y_test_1, yp)\n",
    "    f1 = measure_f1_score(y_test_1, yp)\n",
    "    accs.append(acc)\n",
    "    f1s.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08906948394961398, 0.08906948394961398, 0.08906948394961398, 0.08906948394961398, 0.08906948394961398, 0.08906948394961398, 0.08906948394961398, 0.08906948394961398, 0.08906948394961398, 0.08906948394961398]\n",
      "[0.16356988284456384, 0.16356988284456384, 0.16356988284456384, 0.16356988284456384, 0.16356988284456384, 0.16356988284456384, 0.16356988284456384, 0.16356988284456384, 0.16356988284456384, 0.16356988284456384]\n"
     ]
    }
   ],
   "source": [
    "print(accs)\n",
    "print(f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(gammas,accs,\"r\")\n",
    "plt.plot(gammas, f1s, \"b\")\n",
    "\n",
    "plt.title(\"Mean squared error gd accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.xlabel(\"Gamma\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
